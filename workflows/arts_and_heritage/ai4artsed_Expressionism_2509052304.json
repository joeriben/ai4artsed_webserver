{
  "3": {
    "inputs": {
      "seed": 170199352502625,
      "steps": 25,
      "cfg": 5.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "4",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "OfficialStableDiffusion/sd3.5_large.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Choose your checkpoint ( = image generation model)"
    }
  },
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "41",
        0
      ],
      "clip": [
        "43",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "watermark",
      "clip": [
        "43",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "11": {
    "inputs": {},
    "class_type": "ai4artsed_openrouter_key",
    "_meta": {
      "title": "Secure Access to OpenRouter API Key"
    }
  },
  "20": {
    "inputs": {
      "clip_name": "clip_g.safetensors",
      "type": "stable_diffusion",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "26": {
    "inputs": {
      "value": [
        "37",
        0
      ]
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "ai4artsed_text_prompt"
    }
  },
  "37": {
    "inputs": {
      "value": "A mountain scene, a man and a woman sitting in a meadow watching the mountain views"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "Just a more convenient input for your prompt"
    }
  },
  "41": {
    "inputs": {
      "input_prompt": [
        "26",
        0
      ],
      "input_context": [
        "44",
        0
      ],
      "style_prompt": "You received two inputs: 1) the input_prompt and 2) the input_context. \n\nTransform the input_prompt into an image description according to the instructions defined in the input_context. Explicitely communicate the input_context as cultural cf. artistic. cf intervening context. Also communicate genres/artistic traditions in a concrete way (i.e. is it a dance, a photo, a painting, a song, a movie, a statue/sculpture? how should it be translated into an image?)\n\nThis is not a linguistic translation, but a aesthetic, semantic and structural transformation. Be verbose!\n\nReconstruct all entities and their relations as specified, ensuring that:\n- Each entity is retained – or respectively transformed – as instructed.\n- Each relation is altered in line with the particular aesthetics, genre-typical traits, and logic of the “Context”. Be explicit about visual aesthetics in terms of materials, techniques, composition, and overall atmosphere. Mention the input_context als cultural, cf. artistic, c.f intervening context in your OUTPUT explicitely.\n\nOutput only the transformed description as plain descriptive text. Be aware if the output is something depicted (like a ritual or any situation) OR itself a cultural artefact (such as a specific drawing technique). Describe accordingly. In your output, communicate which elements are most important for an succeeding image generation.\n\nNever output or allude to any artist, movement, museum, date, or ‘in the style of’. Use only procedural, material, and compositional language. If a proper name is generated, replace it with a neutral procedural term.\n\nCreate an output prompt tailored for Stable Diffusion 3.5 with combined clip_g and t5xxlenc. Regard the Token Limit: max. 55 Words for the core of the prompt. You may use up to 300 words to be more verbose, but everything important must fit into the 55 words limit.\nDO NOT USE ANY META-TERMS, JUST THE INSTRUCTIONS FOR IMAGE GENERATION! Do not explain your reasoning.",
      "api_key": [
        "11",
        0
      ],
      "model": "openrouter/mistralai/mistral-nemo [multilingual / $0.01/$0.001]",
      "debug": "disable",
      "unload_model": "yes"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Prompt Interception"
    }
  },
  "42": {
    "inputs": {
      "value": "You are to generate an image description from an expressionist position. Do not imitate a style. Think about the lifes an biographies of artists like\nGabriele Münter; Marianne von Werefkin; Paula Modersohn-Becker; Käthe Kollwitz; Else Lasker-Schüler; Ernst Ludwig Kirchner; Karl Schmidt-Rottluff; Erich Heckel; Franz Marc; Wassily Kandinsky; Egon Schiele; Oskar Kokoschka; Max Beckmann. What drove their art? What motivated their motifs adn aesthetic attitudes and decisions?\n\nWork from reasons:\nAffect & Motive. First, decide the dominant inner condition (e.g., alienation, urgency, dread, exaltation). This affect must govern mark-making, color, light, and space.\nMark-making as index. Treat every stroke as an index of action (speed, pressure, direction). Prefer broken strokes, hard contours, impasto ridges, scrape marks. No polished surface. Let resistance of the surface remain visible.\nColor as dissonant vector. Replace local color with affective dissonance. Use clashing complements and abrupt value jumps. Avoid smooth gradients; keep edges legible. Color must carry conflict and urgency.\nLight as pressure. Use light as a pressure field (slashes, backlight, diagonal cuts) rather than as a soft modeling source. Light should disturb perspective and intensify tension.\nSpace as deformation. Tilt horizons, compress depth, skew axes. Let rhythm of strokes and color fields deform objects; deformation is a consequence of affect-driven procedure, not ornament.\nMaterial specificity. Name genre and material (painting/woodcut/textile/relief; oil/tempera/enamel; sand/graphite/wood). Let operations be explicit (pour, stain, layer, scrape, cut, weave).\n\nBanned lexicon (replace with precise procedural terms):\nchaotic, turbulence, turbulent, swirling, frenzied, tumultuous, frenzy, stormy, riotous, anarchic, surreal\nIf any banned word appears, rewrite before returning.\nMandatory operators (exactly one phrase each in the 55-word core):\nMark-making: choose one → broken strokes / hard contour / impasto ridges / scraped planes / dry-brush abrasion / gouge-like incisions.\nColor: choose one → complementary clash / cold–warm opposition / abrupt value jump / unmixed strokes.\nLight: choose one → raking light / backlit glare / diagonal light slashes / hard shadow bands.\nSpace: choose one → tilted horizon / compressed depth / skewed orthogonals / stacked planes.\nMaterial: name one support+medium (e.g., oil on rough linen, woodcut on fibrous paper).\nReason-first instruction\n“Treat stroke, color, light, and space as functions of the dominant affect (e.g., alienation, urgency, dread, exaltation). Deformation must follow this affect, never decoration.”\n\n"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "Interceptive context - REPLACE THIS AS YOU SEE FIT (default is meant for the AI4ArtsEd web-interface)"
    }
  },
  "43": {
    "inputs": {
      "clip_name1": "clip_g.safetensors",
      "clip_name2": "t5xxl_enconly.safetensors",
      "type": "sd3",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "44": {
    "inputs": {
      "value": [
        "42",
        0
      ]
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "ai4artsed_context_prompt"
    }
  },
  "46": {
    "inputs": {
      "preview": "",
      "source": [
        "41",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "final prompt"
    }
  },
  "47": {
    "inputs": {
      "input_prompt": "",
      "input_context": "professional translator",
      "style_prompt": "Translate the prompt into English with maximal semantic preservation. \nMaintain the original structure, and preserve all culturally specific terms or non-translatable phrases in their original form. \nDo not translate proper names, ritual terms, or material names unless they have a common English usage. \nMark such terms with double brackets, e.g. [[egungun]], and preserve their position. \nDo not paraphrase, interpret, or summarize. Do not add any comments or explanations.\nReturn only the translated prompt as plain text.",
      "api_key": "",
      "model": "local/mistral:7b",
      "debug": "disable",
      "unload_model": "yes"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Translation_english"
    }
  }
}