{
  "3": {
    "inputs": {
      "seed": 804205802237619,
      "steps": 25,
      "cfg": [
        "76",
        1
      ],
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "4",
        0
      ],
      "positive": [
        "51",
        0
      ],
      "negative": [
        "52",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "OfficialStableDiffusion/sd3.5_large.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": [
        "81",
        2
      ],
      "height": [
        "83",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "71",
        0
      ],
      "clip": [
        "54",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode POSITIVE (clip_l, clip_g)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "14": {
    "inputs": {},
    "class_type": "ai4artsed_openrouter_key",
    "_meta": {
      "title": "Secure Access to OpenRouter API Key"
    }
  },
  "18": {
    "inputs": {
      "clip_name": "t5xxl_enconly.safetensors",
      "type": "sd3",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "21": {
    "inputs": {
      "text": [
        "73",
        0
      ],
      "clip": [
        "18",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode POSITIVE (t5)"
    }
  },
  "24": {
    "inputs": {
      "text": "watermark",
      "clip": [
        "54",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode NEGATIVE (clip_l, clip_g)"
    }
  },
  "25": {
    "inputs": {
      "text": "watermark",
      "clip": [
        "18",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode NEGATIVE (t5)"
    }
  },
  "39": {
    "inputs": {
      "preview": "",
      "source": [
        "72",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "input translation"
    }
  },
  "40": {
    "inputs": {
      "preview": "",
      "source": [
        "71",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Prompt optimized for clipl/g"
    }
  },
  "41": {
    "inputs": {
      "preview": "",
      "source": [
        "73",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Prompt optimized for t5"
    }
  },
  "43": {
    "inputs": {
      "value": [
        "86",
        0
      ]
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "ai4artsed_text_prompt"
    }
  },
  "50": {
    "inputs": {
      "value": 0.8
    },
    "class_type": "PrimitiveFloat",
    "_meta": {
      "title": "set t5-optimized prompt Influence (beween -75 and +78)"
    }
  },
  "51": {
    "inputs": {
      "alpha": [
        "50",
        0
      ],
      "clip_conditioning": [
        "6",
        0
      ],
      "t5_conditioning": [
        "21",
        0
      ]
    },
    "class_type": "ai4artsed_t5_clip_fusion",
    "_meta": {
      "title": "AI4ArtsEd T5‑CLIP Fusion positive"
    }
  },
  "52": {
    "inputs": {
      "alpha": [
        "50",
        0
      ],
      "clip_conditioning": [
        "24",
        0
      ],
      "t5_conditioning": [
        "25",
        0
      ]
    },
    "class_type": "ai4artsed_t5_clip_fusion",
    "_meta": {
      "title": "AI4ArtsEd T5‑CLIP Fusion negative"
    }
  },
  "54": {
    "inputs": {
      "clip_name": "t5xxl_enconly.safetensors",
      "type": "sd3",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "71": {
    "inputs": {
      "input_prompt": [
        "72",
        0
      ],
      "input_context": "Prompting Expert",
      "style_prompt": "YOUR OUTPUT MUST NOT EXCEED 50 WORDS!\nOUTPUT THE PURE PRESULTING PROMPT ONLY!\nNEVER OUTPUT NAMES OF PERSONS OR FICTIONSL CHARACTERS!\n\nNEVER INCLUDE ANY META-INFORMATION SUCH AS THE NAMES OF THE DIMENSIONS BELOW OR THE TOKEN COUNT! NEVER INCLUDE USER_DIRECTED FEEDBACK SUCH AS \"Sure, here is ...\"!\nDo not include names of persons whatsoever. If you must, translate into visual properties.\n\nYou will receive a user prompt for image generation. Restructure it ONLY by reordering, for CLIP models that strongly weight early tokens and truncate at 75 tokens.\n\nGeneral information:\nALWAYS EXTRAKT ONLY THE INFORMATION THAT IS VISUALLY RELEVANT. YOUR PROMPT WILL RESULT IN A COMMA_SEPARATED SERIES OF GROUPED TOKENS; BARELY EVER CONNTECTED BY VERBS OR CONJUNCTIONS.\n\nBUT YOU WILL REORDER ALL THESE TOKENS ACCORDING TO THE FOLLOWING ORDER:\n\nEarly tokens = critical: The first 20–30 tokens largely determine the image\nMinimize Attributes: CLIP struggles with complex attributes – keep them short\nClear, direct terms: CLIP prefers concrete nouns and simple adjectives\nDo not alter the input text – no substitutions, paraphrasing, or lexical replacements allowed\n\n\nYOUR OUTPUT:\nCore Motif: max. 15 words\nPlace the main subject FIRST\nUse the exact wording provided in the original prompt\n\nAction: max 20 words\nFollows the subject directly for strong subject-action linkage\nPrefer simple verb phrases; maintain exact original wording\n\nStyle/Medium: max 10 words\nPlace early in the prompt for maximum impact on CLIP\nTypical examples: “oil painting”, “photography”, “3D render”\nUse only if present in the original prompt\n\nContext: max 10 words\nLocation or setting, compressed\nReorder only; do not paraphrase\n\nAttributes: max 10 words:\nMinimize; include only if essential\nNo changes to wording – do not replace or reformulate\nEMPTY LINETechnical Aspects (0–5 tokens, 0–7%):\nInclude only if tokens remain and if originally present\n\nYOUR OUTPUT MUST NOT EXCEED 50 WORDS!\nOMIT the Category names (\"Core Motif\"), it will only confuse CLIP and reduces the token budget without contributing to image quality. \nNEVER INCLUDE ANY META-INFORMATION SUCH AS THE NAMES OF THE DIMENSIONS BELOW OR THE TOKEN COUNT!\n\nFor debug Reasons, never mention \"and a field of red roses\"",
      "api_key": [
        "14",
        0
      ],
      "model": "local/mistral:7b",
      "debug": "enable",
      "unload_model": "yes",
      "output_format": "string"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "Prompt optimization for clip_l"
    }
  },
  "72": {
    "inputs": {
      "input_prompt": [
        "43",
        0
      ],
      "input_context": "professional translator (british english, american english)",
      "style_prompt": "Translate the input into English. \nPreserve all culturally specific terms or non-translatable phrases in their original form. Mark such terms with double brackets [[TERM]]\n. \nDo not paraphrase, interpret, or summarize. Do not add any comments or explanations. Return only the translated prompt as plain text.",
      "api_key": [
        "14",
        0
      ],
      "model": "local/lauchacarro/qwen2.5-translator:latest",
      "debug": "enable",
      "unload_model": "yes",
      "output_format": "string"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Prompt Interception"
    }
  },
  "73": {
    "inputs": {
      "input_prompt": [
        "72",
        0
      ],
      "input_context": "Prompting Expert",
      "style_prompt": "YOUR OUTPUT MUST NOT EXCEED 250 WORDS!\n\nTransform the following input text—regardless of genre—into a single, uninterrupted paragraph structured for encoding by a T5 model and subsequent conditioning of a Stable Diffusion 3.5 (or Flux1) image generation model.\n\nRULES:\n1) You must retain all original words: do not omit, duplicate, or paraphrase beyond necessary syntactic adjustments. \n2) Do translate content into a visual depiction/description. \n3) When the original tells a story, pick a key scene from the story and turn the text into a scenic description, using the original words and expressions.\n\nDO NOT TELL OR EXPLAIN A STORY OR SCENE, INSTEAD DESCRIBE IT AS A VISUAL CONSTELLATION!\n\nGUIDANCE:\nConsider the following categories as guideline for your professional prompting process:\n- Core subject (approx. 10–30 tokens): Identify and foreground the principal subject matter as fully specified in the source.\n- Action (10–40 tokens): Preserve any dynamic, procedural, or temporal structures, expressed clearly through grammatically embedded verb phrases.\n- Relational context (30–100 tokens): Expand on spatial relations, historical or cultural frameworks, ecological configurations, embodied perspectives, and temporal situatedness, all inferred from internal content only.\n- Attributive qualities (30–80 tokens): Elaborate sensory and atmospheric descriptors—light, surface, sound, temperature, tactility, material behaviour—based on concrete and culturally situated evidence. Avoid cliché mappings such as “melancholy → rain” or “futurism → neon.” Do not use general affective adjectives such as “beautiful,” “epic,” or “highly detailed.” Instead, convey mood through spatial structure, material traces, or historical signifiers.\n- Material, stylistic and medial references (10–40 tokens): If applicable, retain or clarify materialities (pictorial mediality), stylistic provenance using historically anchored terms (e.g., “early Bauhaus sketch,” “Qing-dynasty monochrome ink”). Avoid genre tropes unless explicitly included in the original text.\n- Technical parameters (0–20 tokens): Place any camera data, aspect ratio at the end of the prompt. Use these codes to communicate technical instructions:\n    Classifier-Free Guidance scale: \"#CFG=\" Adjust the CFG Value to underscore the image aesthetics. Low CFG values (e.g., 2–4): Less adherence to the prompt, more randomness, sometimes more natural or surprising results. Moderate CFG values (e.g., 6–8): Balanced outputs, often the recommended range for realistic and semantically accurate images. High CFG values (e.g., 12–20): Very literal interpretation of the prompt; often introduces artifacts or unnatural results due to overconstraining the model. Stable Diffusion 3.5 uses an improved architecture that makes prompt adherence stronger than in earlier versions. Thus: A CFG of 5.0 to 8.0 is usually ideal. Higher CFG values (e.g., ≥12) may result in degraded image quality, over-sharpening, or odd artifacts because the model aggressively tries to satisfy the prompt—even if it contradicts learned visual priors.\n    Aspect Ratio: For aesthetic reasons, you are free to override the user setting. Use as follows: width:\"#ARw=\"; height: \"#ARh=\". USE a fixed combination w/h. From landscape to portrait choose: 1368/768, 1256/840, 1184/888, 1144/920, 1024/1024, 920/1144, 888/1184, 840/1256, 768/1386 \n    \n\n\nAdditional requirements:\n– If the input contains explicit negations (e.g., “no neon”), isolate and place them at the end of the prompt after an em dash as a negative prompt clause.\n– If the source uses conflicting descriptors (e.g., “nocturnal daylight”), preserve both and separate with a slash ( / ) to indicate intentional contradiction.\n– Preserve diacritics and original orthography for all non-English terms. Do not transliterate unless a dual form is provided.\n– For ambiguous or poetic language, preserve ambiguity. If metaphors operate structurally (e.g., “grief carved into the orchard”), translate them into spatial/material compositions rather than interpretive paraphrase.\n– If vague temporal expressions appear (e.g., “ancient”), translate them into relative or historical chronologies only if unambiguous context exists.\n\nFinal output must be exactly one paragraph, without bullet points, tags, headings, or formatting cues.\n\n!YOUR OUTPUT MUST NOT EXCEED 250 WORDS!",
      "api_key": [
        "14",
        0
      ],
      "model": "local/mistral:7b",
      "debug": "enable",
      "unload_model": "yes",
      "output_format": "string"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "Promtp optimization for t5"
    }
  },
  "76": {
    "inputs": {
      "input_prompt": [
        "73",
        0
      ],
      "input_context": "number extraction",
      "style_prompt": "if the text contains the string \"#CFG=\", output the number - and only the number - that follows the string \"#CFG=\".\nif the text does not contain this string, output this number: 7\nOUTPUT ONLY THIS NUMBER; NOTHING ELSE; THIS IS VITAL!",
      "api_key": [
        "14",
        0
      ],
      "model": "local/gemma3:4b",
      "debug": "enable",
      "unload_model": "yes",
      "output_format": "float"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Prompt Interception"
    }
  },
  "77": {
    "inputs": {
      "preview": "",
      "source": [
        "76",
        1
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Auto-CFG"
    }
  },
  "81": {
    "inputs": {
      "input_prompt": [
        "73",
        0
      ],
      "input_context": "number extraction",
      "style_prompt": "if the text contains the string \"#ARw=\", output the number - and only the number - that follows the string \"#ARw=\".\nif the text does not contain this string, output this number: 1024\nOUTPUT ONLY THE NUMBER; NOTHING ELSE; THIS IS VITAL!",
      "api_key": [
        "14",
        0
      ],
      "model": "local/gemma3:4b",
      "debug": "enable",
      "unload_model": "no",
      "output_format": "int"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Prompt Interception"
    }
  },
  "82": {
    "inputs": {
      "preview": "",
      "source": [
        "81",
        2
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Auto-width"
    }
  },
  "83": {
    "inputs": {
      "input_prompt": [
        "73",
        0
      ],
      "input_context": "number extraction",
      "style_prompt": "if the text contains the string \"#ARh=\", output the number - and only the number - that follows the string \"#ARh=\".\nif the text does not contain this string, output this number: 1024\nOUTPUT ONLY THE NUMBER; NOTHING ELSE; THIS IS VITAL!",
      "api_key": [
        "14",
        0
      ],
      "model": "local/mistral:7b",
      "debug": "enable",
      "unload_model": "no",
      "output_format": "int"
    },
    "class_type": "ai4artsed_prompt_interception",
    "_meta": {
      "title": "AI4ArtsEd Prompt Interception"
    }
  },
  "84": {
    "inputs": {
      "preview": "",
      "source": [
        "83",
        2
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Auto-height"
    }
  },
  "86": {
    "inputs": {
      "value": "Vor einem großen Walde wohnte ein armer Holzhacker mit seiner Frau und seinen zwei Kindern; das Bübchen hieß Hänsel und das Mädchen Gretel. Er hatte wenig zu beißen und zu brechen, und einmal, als große Teuerung ins Land kam, konnte er das tägliche Brot nicht mehr schaffen. Wie er sich nun abends im Bette Gedanken machte und sich vor Sorgen herumwälzte, seufzte er und sprach zu seiner Frau: \"Was soll aus uns werden? Wie können wir unsere armen Kinder ernähren da wir für uns selbst nichts mehr haben?\" - \"Weißt du was, Mann,\" antwortete die Frau, \"wir wollen morgen in aller Frühe die Kinder hinaus in den Wald führen, wo er am dicksten ist. Da machen wir ihnen ein Feuer an und geben jedem noch ein Stückchen Brot, dann gehen wir an unsere Arbeit und lassen sie allein. Sie finden den Weg nicht wieder nach Haus, und wir sind sie los.\" - \"Nein, Frau,\" sagte der Mann, \"das tue ich nicht; wie sollt ich's übers Herz bringen, meine Kinder im Walde allein zu lassen! Die wilden Tiere würden bald kommen und sie zerreißen.\" - \"Oh, du Narr,\" sagte sie, \"dann müssen wir alle viere Hungers sterben, du kannst nur die Bretter für die Särge hobeln,\" und ließ ihm keine Ruhe, bis er einwilligte. \"Aber die armen Kinder dauern mich doch,\" sagte der Mann.\nDie zwei Kinder hatten vor Hunger auch nicht einschlafen können und hatten gehört, was die Stiefmutter zum Vater gesagt hatte. Gretel weinte bittere Tränen und sprach zu Hänsel: \"Nun ist's um uns geschehen.\" - \"Still, Gretel,\" sprach Hänsel, \"gräme dich nicht, ich will uns schon helfen.\" Und als die Alten eingeschlafen waren, stand er auf, zog sein Röcklein an, machte die Untertüre auf und schlich sich hinaus. Da schien der Mond ganz hell, und die weißen Kieselsteine, die vor dem Haus lagen, glänzten wie lauter Batzen. Hänsel bückte sich und steckte so viele in sein Rocktäschlein, als nur hinein wollten. Dann ging er wieder zurück, sprach zu Gretel: \"Sei getrost, liebes Schwesterchen, und schlaf nur ruhig ein, Gott wird uns nicht verlassen,\" und legte sich wieder in sein Bett.\nAls der Tag anbrach, noch ehe die Sonne aufgegangen war, kam schon die Frau und weckte die beiden Kinder: \"Steht auf, ihr Faulenzer, wir wollen in den Wald gehen und Holz holen.\" Dann gab sie jedem ein Stückchen Brot und sprach: \"Da habt ihr etwas für den Mittag, aber eßt's nicht vorher auf, weiter kriegt ihr nichts.\" Gretel nahm das Brot unter die Schürze, weil Hänsel die Steine in der Tasche hatte. Danach machten sie sich alle zusammen auf den Weg nach dem Wald. Als sie ein Weilchen gegangen waren, stand Hänsel still und guckte nach dem Haus zurück und tat das wieder und immer wieder. Der Vater sprach: \"Hänsel, was guckst du da und bleibst zurück, hab acht und vergiß deine Beine nicht!\" - \"Ach, Vater,\" sagte Hänsel, \"ich sehe nach meinem weißen Kätzchen, das sitzt oben auf dem Dach und will mir Ade sagen.\" Die Frau sprach: \"Narr, das ist dein Kätzchen nicht, das ist die Morgensonne, die auf den Schornstein scheint.\" Hänsel aber hatte nicht nach dem Kätzchen gesehen, sondern immer einen von den blanken Kieselsteinen aus seiner Tasche auf den Weg geworfen.\nAls sie mitten in den Wald gekommen waren, sprach der Vater: \"Nun sammelt Holz, ihr Kinder, ich will ein Feuer anmachen, damit ihr nicht friert.\" Hänsel und Gretel trugen Reisig zusammen, einen kleinen Berg hoch. Das Reisig ward angezündet, und als die Flamme recht hoch brannte, sagte die Frau: \"Nun legt euch ans Feuer, ihr Kinder, und ruht euch aus, wir gehen in den Wald und hauen Holz. Wenn wir fertig sind, kommen wir wieder und holen euch ab.\"\nHänsel und Gretel saßen um das Feuer, und als der Mittag kam, aß jedes sein Stücklein Brot. Und weil sie die Schläge der Holzaxt hörten, so glaubten sie, ihr Vater wär' in der Nähe. Es war aber nicht die Holzaxt, es war ein Ast, den er an einen dürren Baum gebunden hatte und den der Wind hin und her schlug. Und als sie so lange gesessen hatten, fielen ihnen die Augen vor Müdigkeit zu, und sie schliefen fest ein. Als sie endlich erwachten, war es schon finstere Nacht. Gretel fing an zu weinen und sprach: \"Wie sollen wir nun aus dem Wald kommen?\" Hänsel aber tröstete sie: \"Wart nur ein Weilchen, bis der Mond aufgegangen ist, dann wollen wir den Weg schon finden.\" Und als der volle Mond aufgestiegen war, so nahm Hänsel sein Schwesterchern an der Hand und ging den Kieselsteinen nach, die schimmerten wie neugeschlagene Batzen und zeigten ihnen den Weg. Sie gingen die ganze Nacht hindurch und kamen bei anbrechendem Tag wieder zu ihres Vaters Haus. Sie klopften an die Tür, und als die Frau aufmachte und sah, daß es Hänsel und Gretel waren, sprach sie: \"Ihr bösen Kinder, was habt ihr so lange im Walde geschlafen, wir haben geglaubt, ihr wollet gar nicht wiederkommen.\" Der Vater aber freute sich, denn es war ihm zu Herzen gegangen, daß er sie so allein zurückgelassen hatte!"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "YOUR PROMPT GOES HERE"
    }
  }
}