# Session 71 Handover: LTX-Video Integration

**Date**: 2025-11-25
**Branch**: `develop`
**Commit**: `eeb6176`

---

## Was wurde in dieser Session gemacht?

### 1. Initiale Anfrage
User wollte: "GPT Image 1 Stage4-Config, aber mit OpenAI Sora als VideolÃ¶sung"

### 2. Problem erkannt
- **OpenAI Sora API existiert nicht Ã¶ffentlich** (404 Fehler)
- Keine verfÃ¼gbare REST API fÃ¼r Sora (Stand Nov 2025)
- Nur Ã¼ber ChatGPT-Subscriptions oder Third-Party Aggregatoren zugÃ¤nglich

### 3. Alternative evaluiert
Recherche nach zugÃ¤nglichen Video-Modellen:
- âŒ OpenRouter: Keine Video-Generierung
- âŒ Runway, Luma: Separate APIs mit Kosten
- âœ… **LTX-Video (Lightricks)**: Open-source, lokal via ComfyUI

**LTX-Video Vorteile**:
- Open-source (Apache 2.0)
- LÃ¤uft lokal Ã¼ber vorhandenes ComfyUI/SwarmUI
- Extension bereits installiert: `ComfyUI-LTXVideo`
- Sehr schnell: 5-15 sec (Distilled: 4-8 Steps!)
- Workshop-geeignet: Consumer GPU friendly (FP8 = 16GB VRAM)

### 4. Implementation durchgefÃ¼hrt

#### Backend
âœ… **Neuer Chunk erstellt**: `devserver/schemas/chunks/output_video_ltx.json`
- ComfyUI Workflow JSON mit 9 Nodes:
  - `LTXVCheckpointLoader` (Model)
  - `LTXVImgToVideo` (Settings: 1216x704, 121 frames)
  - `KSampler` (25 steps, CFG 3.0)
  - `CLIPTextEncode` (positive/negative)
  - `VAEDecode`
  - `VHS_VideoCombine` (30fps output)
- Input mappings fÃ¼r alle Parameter
- Output mapping fÃ¼r Video-File

âœ… **Config migriert**: `sora_video.json` â†’ `ltx_video.json`
- Backend: `openai` â†’ `comfyui`
- `OUTPUT_CHUNK`: `output_video_sora` â†’ `output_video_ltx`
- Parameters angepasst (WIDTH, HEIGHT, FRAMES, STEPS, CFG, FPS)
- Meta updated (GPU required, VRAM 16GB, duration 5-15 sec)

âœ… **Alt-Dateien deprecated**:
- `output_video_sora.json.DEPRECATED`

#### Frontend
âœ… **Vue Config updated**: `text_transformation.vue`
- Video-Kategorie aktiviert (war disabled)
- Config-ID: `sora_video` â†’ `ltx_video`
- Label: "LTX Video"
- Icon: âš¡ (statt ðŸŽ¬)
- Description: "Schnelle lokale Videogenerierung"

#### Dokumentation
âœ… **Setup-Guide erstellt**: `docs/LTX_VIDEO_MODEL_SETUP.md`
- 3 Model-Optionen dokumentiert
- Download-Links (HuggingFace)
- Q8 Kernels Installation
- Troubleshooting

---

## Aktueller Status

### Was funktioniert
âœ… Backend-Code komplett (Workflow, Config, Mappings)
âœ… Frontend aktiviert (UI zeigt LTX Video an)
âœ… ComfyUI-LTXVideo Extension bereits installiert
âœ… Git committed & dokumentiert

### Was NICHT funktioniert
âŒ **LTX-Video Model nicht heruntergeladen**
âŒ **Integration nicht getestet** (kann nicht laufen ohne Model)

---

## Tasks fÃ¼r nÃ¤chste Session

### Task 1: LTX-Video Model Installation (PRIORITÃ„T 1)

**WICHTIG**: Recherche VORHER wie das fÃ¼r SwarmUI korrekt geht!

#### Recherche-Fragen klÃ¤ren:
1. **Wo speichert SwarmUI Models?**
   - Standard: `/home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/models/checkpoints/`
   - Oder separates SwarmUI Models-Directory?
   - Check: SwarmUI Settings/Config fÃ¼r Model-Pfade

2. **Welches LTX-Model ist optimal?**
   - `ltxv-13b-0.9.7-distilled.safetensors` (26GB, schnellst, 4-8 steps)
   - `ltxv-13b-0.9.7-distilled-fp8.safetensors` (13GB, quantized, RTX 4090)
   - Legacy `ltx-video-2b-v0.9.safetensors` (veraltet, NICHT verwenden)

   **Empfehlung**: Distilled FP8 fÃ¼r Balance Speed/VRAM

3. **Braucht SwarmUI spezielle Model-Registration?**
   - Muss Model in SwarmUI UI registriert werden?
   - Oder reicht ComfyUI checkpoints Directory?
   - Check: SwarmUI Model Management

4. **Q8 Kernels nÃ¶tig fÃ¼r FP8?**
   - README sagt: "Important: install q8_kernels for quantized"
   - Aber neuere Versionen: "running natively in ComfyUI"
   - Test: Mit und ohne Q8 Kernels probieren

#### Installation Steps (NACH Recherche):

```bash
# 1. Model Download (Beispiel fÃ¼r FP8)
cd /home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/models/checkpoints/
wget https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltxv-13b-0.9.7-distilled-fp8.safetensors

# 2. (Optional) Q8 Kernels falls nÃ¶tig
cd /home/joerissen/ai/SwarmUI/dlbackend/ComfyUI
source ../../venv/bin/activate  # Falls venv
pip install git+https://github.com/Lightricks/LTXVideo-Q8-Kernels.git

# 3. Verify installation
ls -lh models/checkpoints/ltxv*
```

#### Config-Update nach Download:

File: `devserver/schemas/chunks/output_video_ltx.json`

```json
{
  "3": {
    "inputs": {
      "ckpt_name": "ltxv-13b-0.9.7-distilled-fp8.safetensors"  // â† Aktuellen Dateinamen eintragen
    },
    "class_type": "LTXVCheckpointLoader"
  }
}
```

**Falls Distilled Model verwendet**:
- Steps reduzieren: `"default": 6` (statt 25)
- In Config und Chunk anpassen

---

### Task 2: DevServer Integration Testing (PRIORITÃ„T 2)

#### Test-Workflow:
1. **Backend Restart** (lÃ¤dt neue Configs):
   ```bash
   cd /home/joerissen/ai/ai4artsed_webserver
   ./1_stop_all.sh
   ./3_start_backend_dev.sh
   ```

2. **Config-Loading prÃ¼fen**:
   ```bash
   # Check ob ltx_video.json geladen wird
   curl http://localhost:17802/api/schema/configs/output | jq '.[] | select(.id == "ltx_video")'
   ```

3. **Frontend Test** (Phase2 Interface):
   - http://localhost:5173
   - Video-Kategorie auswÃ¤hlen
   - âš¡ LTX Video sollte sichtbar sein

4. **End-to-End Test**:
   ```bash
   curl -X POST http://localhost:17802/api/schema/pipeline/execute \
     -H "Content-Type: application/json" \
     -d '{
       "schema": "dada",
       "input_text": "A red car driving through a forest",
       "output_config": "ltx_video",
       "execution_mode": "eco",
       "safety_level": "youth",
       "user_language": "en"
     }'
   ```

#### Erwartetes Verhalten:
1. Stage 1-3: Text-Processing (wie bei Images)
2. Stage 4: ComfyUI Workflow execution
3. Output: Video file (MP4) in run directory

#### MÃ¶gliche Fehler & Fixes:

**Error: "Model not found"**
â†’ Check `ckpt_name` in chunk matches downloaded file
â†’ Verify ComfyUI can see the model: SwarmUI UI â†’ Models

**Error: "Node LTXVCheckpointLoader not found"**
â†’ ComfyUI-LTXVideo extension nicht geladen
â†’ Restart ComfyUI backend

**Error: "VHS_VideoCombine not found"**
â†’ Video Helper Suite Extension fehlt
â†’ Install: `cd custom_nodes && git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite`

**Error: "CUDA out of memory"**
â†’ Resolution reduzieren: 1216x704 â†’ 768x512
â†’ Oder: FP8 quantized model verwenden

**Generation zu langsam (>60 sec)**
â†’ Check ob Distilled Model verwendet wird
â†’ Steps auf 6 reduzieren (nicht 25!)

---

## Architektur-Referenz

### File-Struktur
```
devserver/schemas/
â”œâ”€â”€ chunks/
â”‚   â”œâ”€â”€ output_video_ltx.json          â† ComfyUI Workflow + Mappings
â”‚   â””â”€â”€ output_video_sora.json.DEPRECATED
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ ltx_video.json             â† High-level Config
â”‚       â””â”€â”€ sora_video.json (deleted)
â””â”€â”€ engine/
    â”œâ”€â”€ backend_router.py              â† Routes zu ComfyUI
    â””â”€â”€ pipeline_executor.py           â† FÃ¼hrt Workflow aus

public/ai4artsed-frontend/src/views/
â””â”€â”€ text_transformation.vue            â† Frontend Config-Selection
```

### Workflow-Flow
1. **User wÃ¤hlt**: Phase2 UI â†’ Video â†’ âš¡ LTX Video
2. **Config geladen**: `ltx_video.json` â†’ `OUTPUT_CHUNK: "output_video_ltx"`
3. **Chunk geladen**: `output_video_ltx.json` â†’ ComfyUI Workflow JSON
4. **Backend Router**: Sendet Workflow an SwarmUI ComfyUI Backend
5. **ComfyUI**: FÃ¼hrt Workflow aus (Model load, Sample, Decode, Save)
6. **Output**: Video file zurÃ¼ck zu DevServer â†’ Frontend

### Bestehende ComfyUI-Integration
- **Pattern**: Identisch zu SD3.5 Large (`output_image_sd35_large.json`)
- **Backend**: `backend_router.py` hat bereits ComfyUI-Support
- **Communication**: HTTP API zu SwarmUI/ComfyUI
- **Keine Ã„nderungen nÃ¶tig**: Backend-Code ist generic

---

## Wichtige Hinweise

### DO NOT
- âŒ NICHT "ltx-video-2b-v0.9.safetensors" verwenden (veraltet)
- âŒ NICHT Node-Namen Ã¤ndern (mÃ¼ssen zu ComfyUI-LTXVideo passen)
- âŒ NICHT Steps >10 bei Distilled Models (ineffizient)

### DO
- âœ… Recherche VORHER: SwarmUI Model-Handling
- âœ… FP8 quantized bevorzugen (schneller, weniger VRAM)
- âœ… Steps auf 6 bei Distilled Models
- âœ… Logs checken: SwarmUI + DevServer Backend

### Debug-Commands
```bash
# SwarmUI Status
ps aux | grep -i swarm

# ComfyUI Backend Logs
tail -f /home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/comfyui.log

# DevServer Backend Logs
tail -f /home/joerissen/ai/ai4artsed_webserver/devserver/logs/backend.log

# Check Models in ComfyUI
curl http://localhost:7820/object_info | jq '.LTXVCheckpointLoader'
```

---

## Ressourcen

### Dokumentation
- `docs/LTX_VIDEO_MODEL_SETUP.md` (diese Session)
- `devserver/schemas/chunks/output_video_ltx.json` (Workflow)
- `/home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/custom_nodes/ComfyUI-LTXVideo/README.md`

### External Links
- [LTX-Video HuggingFace](https://huggingface.co/Lightricks/LTX-Video)
- [ComfyUI-LTXVideo GitHub](https://github.com/Lightricks/ComfyUI-LTXVideo)
- [Q8 Kernels](https://github.com/Lightricks/LTXVideo-Q8-Kernels)
- [SwarmUI Docs](https://swarmui.net/)

### Example Workflows
Check ComfyUI-LTXVideo fÃ¼r Referenz-Workflows:
```bash
ls /home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/custom_nodes/ComfyUI-LTXVideo/example_workflows/
```

---

## Success Criteria

Session erfolgreich wenn:
1. âœ… LTX Model heruntergeladen & in ComfyUI verfÃ¼gbar
2. âœ… Config zeigt korrekten Model-Namen
3. âœ… DevServer Backend startet ohne Fehler
4. âœ… Phase2 UI zeigt "âš¡ LTX Video"
5. âœ… Test-Generation produziert Video-File
6. âœ… Video spielt ab (4 sec, 30fps, sinnvoller Content)

---

## Commit Reference
```
feat: Replace Sora with LTX-Video for local video generation
Commit: eeb6176
Branch: develop
Files changed: 21 files, +1585/-99 lines
```

---

**Next Session**: START WITH RESEARCH! â†’ SwarmUI Model Installation Best Practices
