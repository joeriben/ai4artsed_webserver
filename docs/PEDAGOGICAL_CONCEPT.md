# AI4ArtsEd: Pädagogisches Konzept

**Kritisches und kreatives Experimentieren mit generativer KI in der kulturellen Bildung**

*Konzeptpapier zur theoretischen Fundierung der Plattform*

Dieses Dokument wurde vollautomatisiert erstellt (Claude 5 Opus).

---

## Einleitung: Warum AI4ArtsEd?

### Das Problem

Generative KI-Systeme wie Stable Diffusion, DALL-E oder Midjourney sind zu mächtigen Werkzeugen der Bildproduktion geworden. Sie versprechen: "Beschreibe, was du willst, und die KI erzeugt es." Diese Versprechen sind faszinierend, aber auch problematisch.

**Das erste Problem ist die Black Box.** Nutzer:innen geben einen kurzen Text ein ("a beautiful sunset over the ocean") und erhalten ein Bild. Was dazwischen passiert, bleibt unsichtbar. Die KI wird zur Wunscherfüllungsmaschine, deren Funktionsweise nicht hinterfragt wird.

**Das zweite Problem ist die Passivität.** Die typische Interaktion mit generativer KI folgt einem Konsummuster: Ich sage, was ich will, die Maschine liefert. Die kreative Arbeit – das Nachdenken über Perspektiven, Materialien, Stile, Bedeutungen – wird an die KI delegiert. Der Mensch wird zum Auftraggeber, nicht zum Gestalter.

**Das dritte Problem ist die Oberflächlichkeit.** "Prompt Engineering" reduziert kreative Arbeit auf die Optimierung von Stichworten. Welche Worte bringen das beste Ergebnis? Diese Frage ersetzt die eigentlich wichtigen: Was will ich eigentlich ausdrücken? Wie kann ich meine Idee aus verschiedenen Blickwinkeln verstehen? Was macht ein Bild zu meinem Bild?

### Die Antwort

AI4ArtsEd ist eine Experimentierplattform, die diese Probleme adressiert. Sie wurde entwickelt für die kulturelle Bildung mit Kindern und Jugendlichen (8-17 Jahre), ist aber in ihrem Konzept allgemeingültig.

Die Plattform verfolgt nicht das Ziel, "bessere Bilder" zu erzeugen. Sie verfolgt das Ziel, den Prozess der Bilderzeugung sichtbar, verstehbar und gestaltbar zu machen. Generative KI wird dabei nicht als Werkzeug betrachtet, das man möglichst effizient bedienen sollte, sondern als Gegenstand kritischer und kreativer Auseinandersetzung.

Die zentralen Designprinzipien sind:
1. **Trennung von WAS und WIE** – Idee und Regeln werden getrennt eingegeben
2. **LLM als Co-Akteur** – Das Sprachmodell ist sichtbarer Mitgestalter, nicht unsichtbare Magie
3. **Sichtbarkeit der Verarbeitung** – Jeder Zwischenschritt kann beobachtet und verändert werden
4. **Kritisches Erkunden** – Die Grenzen und Eigenheiten der Modelle werden erforscht
5. **Zirkularität** – Iteration und Wiederverwendung statt linearer Produktion
6. **Pädagogische Begleitung** – Die Plattform entfaltet ihren Wert durch reflektierende Begleitung

Die folgenden Abschnitte erläutern diese Prinzipien im Detail.

---

## 1. Das WAS/WIE-Prinzip: Idee und Regeln trennen

### Das Konzept

In der typischen Interaktion mit generativer KI gibt der Mensch einen Prompt ein, der alles vermischt: die Grundidee, stilistische Vorgaben, technische Parameter, gewünschte Atmosphäre. "A beautiful sunset over the ocean in the style of Monet, oil painting, warm colors, peaceful mood, 4k, highly detailed."

Diese Vermischung macht unsichtbar, welche Entscheidungen eigentlich getroffen werden. Was ist die Idee? Was sind die Regeln? Welche Regeln habe ich bewusst gewählt, welche unbewusst übernommen?

AI4ArtsEd trennt diese Ebenen explizit:

**WAS (Die Idee)**
- Was soll entstehen?
- Was ist der Gegenstand, das Thema, die Situation?
- Was will ich ausdrücken?

**WIE (Die Regeln)**
- Aus welcher Perspektive wird beschrieben?
- Welche Materialien, Techniken, Stile werden verwendet?
- Welche Aspekte werden betont, welche weggelassen?
- Nach welchen Prinzipien wird die Idee in eine Beschreibung übersetzt?

### Warum diese Trennung?

**1. Bewusstwerdung über Entscheidungen**

Wenn ich gezwungen bin, Regeln explizit zu formulieren, werde ich mir bewusst, dass ich Entscheidungen treffe. "Beschreibe aus der Perspektive eines Vogels" ist eine andere Entscheidung als "Beschreibe aus der Perspektive einer Ameise". Beide sind möglich. Beide erzeugen völlig unterschiedliche Ergebnisse. Die Wahl ist meine kreative Entscheidung.

**2. Variierbarkeit derselben Idee**

Mit der WAS/WIE-Trennung kann dieselbe Idee mit unterschiedlichen Regeln verarbeitet werden. Ein "Waldspaziergang" kann beschrieben werden:
- aus der Perspektive eines Kindes
- aus der Perspektive eines Biologen
- im Stil einer technischen Zeichnung
- als impressionistisches Gemälde
- als Klanglandschaft

Die Idee bleibt gleich. Die Regeln verändern alles. Diese Erfahrung macht die Gestaltungsmacht der Regeln spürbar.

**3. Lernbarkeit von Regeln**

Vorgefertigte Regel-Konfigurationen dienen als Beispiele: Wie könnte eine Regel aussehen? Welche Aspekte kann ich überhaupt regeln? Das Ziel ist nicht, diese Vorlagen zu verwenden, sondern von ihnen zu lernen, um eigene Regeln zu formulieren.

### Beispiel

**Idee (WAS):** "Ein Frühstückstisch am Sonntagmorgen"

**Mögliche Regeln (WIE):**

*Regel A: Bauhaus-Perspektive*
"Reduziere alles auf geometrische Grundformen. Verwende nur Primärfarben und industrielle Materialien. Form folgt Funktion."

*Regel B: Kinderperspektive*
"Beschreibe, was ein fünfjähriges Kind sehen und interessant finden würde. Verwende einfache Worte und betone das Spielerische."

*Regel C: Kulinarische Fachsprache*
"Beschreibe präzise Zubereitungsarten, Texturen und Geschmacksnoten. Verwende gastronomische Fachbegriffe."

Dieselbe Idee, drei völlig verschiedene Beschreibungen, drei völlig verschiedene Bilder.

### Pädagogische Implikation

Die WAS/WIE-Trennung macht den kreativen Prozess explizit. Sie zeigt: Ein Bild entsteht nicht einfach aus einer "Idee", sondern aus der Kombination von Idee und Gestaltungsentscheidungen. Diese Entscheidungen können bewusst getroffen werden. Sie können reflektiert, variiert, verglichen werden.

Das ist keine Technik des "Prompt Engineering". Es ist eine Methode der ästhetischen Bildung.

---

## 2. Das LLM als Co-Akteur: Faszination und Problem

### Was ist ein Co-Akteur?

In AI4ArtsEd wird das Sprachmodell (Large Language Model, LLM) nicht als "Werkzeug" oder "Assistent" bezeichnet, sondern als **Co-Akteur**. Diese Begriffsswahl ist bewusst und markiert eine zentrale Spannung.

Ein Werkzeug tut, was ich will. Ein Hammer schlägt den Nagel ein, den ich ihm zeige. Die Aktion liegt vollständig bei mir.

Ein Co-Akteur handelt mit. Er bringt etwas Eigenes ein. Er interpretiert, ergänzt, verändert. Das Ergebnis ist nicht einfach die Umsetzung meines Willens, sondern ein gemeinsames Produkt.

### Warum "Co-Akteur"?

Wenn ein Sprachmodell meine Idee ("Ein Waldspaziergang") mit meinen Regeln ("aus der Perspektive eines Biologen") verarbeitet, passiert mehr als mechanische Umsetzung:

- Das Modell **interpretiert**, was "Perspektive eines Biologen" bedeutet
- Es **wählt aus**, welche biologischen Aspekte relevant sind
- Es **formuliert** in einer bestimmten Sprache, mit bestimmten Metaphern
- Es **ergänzt** Details, die ich nicht vorgegeben habe

Das Ergebnis trägt meine Handschrift (Idee + Regeln), aber auch die Handschrift des Modells (Training, Gewichtungen, statistische Muster).

### Das Problem

Diese Co-Akteurschaft ist **faszinierend**, aber auch **problematisch**:

**1. Intransparenz**

Wir wissen nicht, wie das Modell zu seinen Entscheidungen kommt. Warum hat es dieses Wort gewählt und nicht jenes? Warum diese Assoziation und nicht eine andere? Die "Entscheidungen" des Modells sind nicht nachvollziehbar.

**2. Scheinbare Intentionalität**

Sprachmodelle erzeugen Text, der aussieht, als hätte jemand ihn mit Absicht geschrieben. Aber sie haben keine Absichten. Sie berechnen wahrscheinliche Fortsetzungen. Die Illusion von Intention kann irreführen.

**3. Reproduktion von Mustern**

Sprachmodelle sind auf riesigen Textmengen trainiert. Sie reproduzieren die Muster, Vorurteile, Klischees dieser Texte. Was als "Kreativität" erscheint, ist oft statistische Mittelung.

**4. Verdeckte Autorenschaft**

Wenn das Modell mitgestaltet, wer ist dann der Autor des Ergebnisses? Diese Frage ist für Bildung wichtig: Ist das noch "mein" Werk?

### Pädagogische Konsequenz

AI4ArtsEd versucht nicht, diese Probleme zu lösen oder zu verbergen. Im Gegenteil: Die Plattform macht die Co-Akteurschaft **sichtbar und erfahrbar**.

Nutzer:innen sollen:
- **sehen**, was das Modell aus ihrer Eingabe macht
- **vergleichen**, wie verschiedene Modelle unterschiedlich reagieren
- **eingreifen** können, wenn das Ergebnis nicht passt
- **reflektieren**, was "ihr" Anteil und was "Modell-Anteil" ist

Die Faszination bleibt: Es ist erstaunlich, was diese Modelle können. Aber die Faszination wird begleitet von kritischer Distanz. Das Modell ist kein Orakel. Es ist ein statistischer Textgenerator mit beeindruckenden Fähigkeiten und echten Grenzen.

### Kontrast zu üblichen Narrativen

Die meisten KI-Anwendungen präsentieren sich als "magische Assistenten" oder "intelligente Helfer". Sie verbergen die Verarbeitung, um "nahtlose" Erlebnisse zu erzeugen.

AI4ArtsEd geht den entgegengesetzten Weg: Die Verarbeitung wird **ausgestellt**. Der Co-Akteur tritt in Erscheinung. Die Naht wird sichtbar. Genau das ermöglicht Lernen.

---

## 3. Kritisches Erkunden: Die Grenzen der Modelle erfahren

### Jenseits von "Prompt Engineering"

Der Begriff "Prompt Engineering" suggeriert: Es gibt einen richtigen Weg, mit KI zu sprechen. Wer die richtigen Techniken kennt, bekommt bessere Ergebnisse. Die Aufgabe ist Optimierung.

AI4ArtsEd verfolgt ein anderes Ziel: **kritisches Erkunden**. Die Frage ist nicht "Wie bekomme ich das beste Ergebnis?", sondern:

- Wie reagiert dieses Modell auf diese Eingabe?
- Was passiert, wenn ich etwas verändere?
- Wo liegen die Grenzen des Verständnisses?
- Welche Muster reproduziert das Modell?
- Was kann es nicht?

### Drei Dimensionen des Erkundens

**1. Modellvergleich**

AI4ArtsEd bietet verschiedene Bildgenerierungsmodelle an: Stable Diffusion 3.5, GPT Image, Gemini, QWEN und andere. Nutzer:innen können denselben Prompt an verschiedene Modelle schicken und die Ergebnisse vergleichen.

Was lernt man dabei?
- Modelle sind nicht neutral. Jedes hat "Vorlieben".
- Derselbe Prompt erzeugt unterschiedliche Bilder.
- Manche Modelle verstehen bestimmte Konzepte besser als andere.
- Es gibt kein "objektiv bestes" Ergebnis.

**2. Prompt-Variation**

Durch die WAS/WIE-Trennung können Nutzer:innen systematisch variieren:
- Dieselbe Idee mit verschiedenen Regeln
- Dieselben Regeln mit verschiedenen Ideen
- Minimale Änderungen, um Reaktionen zu beobachten

Was lernt man dabei?
- Kleine Änderungen können große Unterschiede machen.
- Manche Formulierungen sind "stärker" als andere.
- Modelle haben blinde Flecken.

**3. Grenz-Experimente**

Was passiert, wenn ich:
- absichtlich widersprüchliche Anweisungen gebe?
- Konzepte verlange, die das Modell nicht kennen kann?
- extrem lange oder extrem kurze Prompts verwende?
- in verschiedenen Sprachen kommuniziere?

Was lernt man dabei?
- Modelle scheitern auf interessante Weisen.
- Die "Intelligenz" hat klare Grenzen.
- Fehler sind lehrreich.

### Vom Konsumenten zum Forscher

In der üblichen KI-Nutzung ist der Mensch Konsument: Er bestellt, die KI liefert. Wenn das Ergebnis nicht passt, bestellt er erneut.

AI4ArtsEd positioniert Nutzer:innen als **Forschende**. Sie untersuchen ein System, dessen Funktionsweise nicht vollständig bekannt ist. Sie stellen Hypothesen auf ("Wenn ich X ändere, passiert Y"), testen sie, beobachten, lernen.

Diese forschende Haltung ist ein Bildungsziel. Sie überträgt sich auf andere Kontexte: Wie funktioniert diese Social-Media-Plattform? Welche Muster reproduziert dieser Algorithmus? Wo liegen die Grenzen dieser Technologie?

### Beispiele für Erkenntnisse

Durch kritisches Erkunden können Nutzer:innen entdecken:

- Stable Diffusion 3.5 braucht einen anderen Prompt-Stil als GPT Image
- Manche Modelle tendieren zu "schönen" Bildern, auch wenn das nicht verlangt wurde
- Abstrakte Konzepte werden oft in Klischees übersetzt
- Die Sprache der Beschreibung beeinflusst das Ergebnis (Englisch vs. Deutsch)
- Manche Kombinationen (z.B. "fröhlich" + "Tod") überfordern Modelle

Diese Erkenntnisse sind keine Fakten, die man auswendig lernen könnte. Sie sind **Erfahrungen**, die durch eigenes Experimentieren gewonnen werden.

---

## 4. Sichtbarkeit der Verarbeitung: Die Pipeline ausstellen

### Das Gegenteil von "Seamless"

Moderne Software-Design-Philosophie strebt nach "nahtlosen" Erlebnissen. Der Nutzer soll nicht merken, was im Hintergrund passiert. Komplexität wird versteckt. Die Oberfläche wird "intuitiv".

AI4ArtsEd verfolgt das Gegenteil: **Die Verarbeitung wird sichtbar gemacht.** Jeder Schritt kann beobachtet, verstanden und verändert werden.

### Drei Eingabe-Modi

Die WAS/WIE-Trennung gilt für alle drei Modi der Plattform:

**Text-Modus**: Die Idee wird als Text eingegeben. Dies ist der "klassische" Modus, in dem das LLM die textuelle Idee mit den Regeln verarbeitet.

**Bild-Modus**: Statt Text wird ein Bild hochgeladen. Das Bild *ersetzt* die textuelle Idee – die Regeln werden auf das Bild angewandt. Ein Vision-Modell analysiert das Bild und erzeugt basierend auf Bild + Regeln eine neue Version.

**Multi-Bild-Modus**: Bis zu drei Bilder können hochgeladen werden. Sie *ersetzen gemeinsam* die textuelle Idee. Die Nutzer:in beschreibt, wie die Bilder kombiniert werden sollen. Die Regeln gelten weiterhin.

In allen drei Modi bleibt das Prinzip gleich: WAS (Idee oder Bild) + WIE (Regeln) = verarbeiteter Prompt.

### Die sichtbare Pipeline

Wenn ein:e Nutzer:in eine Idee mit Regeln eingibt und auf "Start" klickt, passiert Folgendes – und all das ist sichtbar:

**Schritt 1: Verarbeitung (Interception)**

Das Sprachmodell kombiniert Idee und Regeln zu einem erweiterten Prompt. Das Ergebnis erscheint in einer Box. Nutzer:innen können lesen, was das Modell aus ihrer Eingabe gemacht hat.

- Wurde die Idee richtig verstanden?
- Wurden die Regeln sinnvoll angewendet?
- Welche Details hat das Modell hinzugefügt?

**Schritt 2: Prompt-Optimierung (bei manchen Modellen)**

Für manche Bildgenerierungsmodelle (z.B. Stable Diffusion 3.5) wird der natürlichsprachliche Prompt in einen technischen Prompt umgewandelt. Auch dieser Schritt ist sichtbar.

- Wie sieht "klassisches Prompting" aus?
- Welche Stichworte und Gewichtungen werden verwendet?
- Was geht bei der Übersetzung verloren?

**Schritt 3: Generierung**

Das Bild (oder Video, Audio, Musik, Code) wird erzeugt. Direkt vor der Generierung erfolgt automatisch die Übersetzung ins Englische, da die Modelle diese Sprache am besten verstehen. Die Dauer ist sichtbar. Das Ergebnis erscheint.

*Anmerkung zur Multimodalität:* AI4ArtsEd ist nicht auf Bilder beschränkt. Dieselbe Pipeline kann Video, Audio, Musik oder sogar generativen Code (p5.js) erzeugen. Die Prinzipien – WAS/WIE-Trennung, sichtbare Verarbeitung, Zirkularität – gelten für alle Medien.

### Eingriffsmöglichkeiten

An jedem Schritt können Nutzer:innen **eingreifen**:

- Den erweiterten Prompt bearbeiten, bevor er weiterverarbeitet wird
- Den optimierten Prompt verändern
- Die Generierung mit veränderten Parametern wiederholen
- Das Ergebnis kopieren und als neue Eingabe verwenden

Diese Eingriffsmöglichkeiten sind nicht nur technische Features. Sie sind **pädagogische Werkzeuge**. Sie machen erfahrbar: Jeder Schritt ist eine Entscheidung. Jede Entscheidung kann verändert werden.

### Warum Sichtbarkeit?

**1. Entmystifizierung**

KI wirkt oft wie Magie. Man gibt etwas ein, etwas kommt heraus, dazwischen liegt ein Geheimnis. Die sichtbare Pipeline zeigt: Es ist keine Magie. Es sind Schritte. Schritte können verstanden werden.

**2. Lernmöglichkeit**

Nur was sichtbar ist, kann analysiert werden. Nur was verändert werden kann, kann experimentell erforscht werden. Sichtbarkeit ist Voraussetzung für Lernen.

**3. Kontrolle**

Wer die Schritte sieht und eingreifen kann, hat Kontrolle. Wer die Schritte nicht sieht, ist passiv. Kontrolle ist Ermächtigung.

**4. Kritische Distanz**

Wenn ich sehe, wie das Modell "denkt" (bzw. rechnet), verliert es seine Aura der Unfehlbarkeit. Ich kann seine Entscheidungen hinterfragen. Ich bleibe kritisch.

### Technische Umsetzung

Die Plattform nutzt eine mehrstufige Pipeline:

1. **Stage 1**: Initiale Verarbeitung und Sicherheitsprüfung
2. **Stage 2**: Interception (LLM kombiniert Idee + Regeln)
3. **Stage 3**: Prompt-Optimierung (modellabhängig)
4. **Stage 4**: Übersetzung ins Englische + Mediengenerierung

Die Übersetzung erfolgt direkt vor der Generierung, da die Bildmodelle Englisch am besten verstehen. Die vorherigen Schritte (Interception, Optimierung) finden in der Sprache der Nutzer:innen statt – so bleibt der Prozess verständlich.

Zwischen den Stages gibt es "Breakpoints": Punkte, an denen die Verarbeitung pausiert und Nutzer:innen den aktuellen Stand sehen und verändern können.

### Konfigurierbare Sprachmodelle

Ein weiterer Aspekt der Sichtbarkeit: Die verwendeten Sprachmodelle sind **pro Funktionsbereich einstellbar**. Für die Interception kann ein anderes Modell verwendet werden als für die Prompt-Optimierung.

Dies hat pädagogischen Wert: Verschiedene Sprachmodelle haben unterschiedliche "Charaktere". Ein Wechsel des Modells verändert nicht nur die Textqualität, sondern auch den Stil, die Assoziationen, die Interpretation der Regeln. Fortgeschrittene Nutzer:innen können dies beobachten und vergleichen.

---

## 5. Zirkularität: Iteration statt Linearität

### Das Problem linearer Workflows

Die meisten generativen KI-Anwendungen folgen einem linearen Modell:

```
Eingabe → Verarbeitung → Ausgabe
```

Der Prozess ist abgeschlossen. Wenn das Ergebnis nicht passt, beginnt man von vorne. Die Ausgabe ist ein Endprodukt.

Kreative Arbeit funktioniert aber anders. Sie ist **zirkulär**:

```
Idee → Versuch → Beobachtung → Anpassung → neuer Versuch → ...
```

Ein Ergebnis ist nie nur Endpunkt. Es ist immer auch Ausgangspunkt für weitere Arbeit.

### Zirkularität in AI4ArtsEd

Die Plattform ist zirkulär gedacht. Obwohl die Oberfläche von oben nach unten organisiert ist, kann an jedem Punkt zurückgegangen, verändert, weitergearbeitet werden:

**Texte sind kopierbar**

Jeder generierte Text (erweiterter Prompt, optimierter Prompt) kann kopiert und an anderer Stelle eingefügt werden. Das Ergebnis der Verarbeitung kann zur neuen Eingabe werden.

**Bilder sind weiterverwendbar**

Generierte Bilder können in den Bild-Modus oder Multi-Bild-Modus geladen werden. Ein generiertes Bild wird zum Ausgangsmaterial für weitere Verarbeitung.

**Regeln sind kombinierbar**

Ein Prompt kann mit einer Regel verarbeitet, das Ergebnis kopiert, und dann mit einer anderen Regel weiterverarbeitet werden. Ketten von Transformationen sind möglich.

### Beispiel: Transformationskette

1. Idee: "Ein Frühstückstisch"
2. Verarbeitung mit Regel "Verniedlicher" → niedlicher, verspielter Prompt
3. Ergebnis kopieren, zurück zum Anfang
4. Mit Regel "Entkitscher" verarbeiten → kritische, distanzierte Version
5. Ergebnis kopieren, weiter mit "Übertreiber" → extreme, übersteigerte Version
6. Zwischendurch eigene Änderungen einfügen

Das Endergebnis ist das Produkt einer **Kette von Transformationen**, nicht einer einzelnen Eingabe. Der Mensch bleibt an jedem Punkt Gestalter.

### Pädagogischer Wert

**1. Prozessorientierung**

Zirkularität betont den Prozess, nicht das Produkt. Der Weg ist wichtig. Die Zwischenschritte sind interessant. Das "fertige" Bild ist nur ein möglicher Zustand.

**2. Experimentierfreude**

Wenn jedes Ergebnis Ausgangspunkt sein kann, sinkt die Hemmschwelle zum Experimentieren. "Falsche" Ergebnisse sind Zwischenschritte, keine Sackgassen.

**3. Reflexion**

Durch Iteration wird sichtbar, wie kleine Änderungen große Unterschiede machen. Die Transformationskette dokumentiert den Denkprozess.

**4. Eigenständigkeit**

Wer Ergebnisse weiterverarbeitet und verändert, macht sie sich zu eigen. Das Endprodukt trägt die Handschrift des Menschen, nicht nur der Maschine.

### Variation und Iteration

AI4ArtsEd unterstützt zwei Arten der Wiederholung:

**Variation**: Derselbe Prompt, aber mit neuem Zufalls-Seed. Das Modell erzeugt ein anderes Bild. Gut zum Erkunden des Möglichkeitsraums.

**Iteration**: Veränderter Prompt, aber derselbe Seed. Das Bild ändert sich entsprechend der Prompt-Änderung. Gut zum Verfeinern einer Idee.

Beide Strategien sind Teil zirkulären Arbeitens.

---

## 6. Experimentelle Workflows: Die Black Box öffnen

### Über die Oberfläche hinaus

Die bisherigen Kapitel beschrieben, wie AI4ArtsEd den "normalen" Workflow von generativer KI sichtbar und gestaltbar macht. Aber die Plattform bietet auch **experimentelle Workflows**, die einen Schritt weiter gehen.

Diese Workflows machen nicht nur die Verarbeitung sichtbar. Sie machen **die innere Struktur der Modelle** ein Stück weit erfahrbar.

### Wie "verstehen" Modelle Text?

Bildgenerierungsmodelle wie Stable Diffusion verarbeiten Text nicht wie Menschen. Sie übersetzen Text in mathematische Vektoren – Listen von Zahlen, die in einem hochdimensionalen Raum Positionen markieren.

Ähnliche Konzepte liegen nahe beieinander. "Hund" und "Welpe" haben ähnliche Vektoren. "Hund" und "Demokratie" liegen weit entfernt.

Diese Vektoren sind normalerweise unsichtbar. Die experimentellen Workflows machen sie **erfahrbar**.

### Surrealizer: Zwei Verständnisse verschmelzen

Stable Diffusion verwendet zwei verschiedene Text-Encoder: **CLIP** und **T5**. Beide übersetzen Text in Vektoren, aber sie "verstehen" anders.

Der Surrealizer-Workflow nutzt **beide Encoder** und **mischt ihre Ergebnisse**:

- Der Text wird von CLIP in Vektor A übersetzt
- Derselbe Text wird von T5 in Vektor B übersetzt
- Die Vektoren werden per Slider in verschiedenen Verhältnissen kombiniert
- Dabei werden die Vektoren im latenten Bedeutungsraum mathematisch "ausgedehnt" und in entferntere Bedeutungsregionen verschoben, mit ungewissem Ergebnis.
- Das Ergebnis: ungewöhnliche Einblicke in latente Bedeutungsräume der Modelle, die über konventionelles Prompting **nicht** erreichbar sind.
- Es kann sehr interessant sein, mit dem Bildergebnis weiterzuarbeiten, z.B. ein Video daraus zu machen.

### Split & Combine: Konzepte trennen und verschmelzen

Dieser Workflow nimmt einen Prompt, der zwei Konzepte enthält (z.B. "eine Katze spielt mit einem Ball"), und erzeugt **vier Bilder**:

1. Das Original (beide Konzepte)
2. Nur das erste Konzept (Katze)
3. Nur das zweite Konzept (Ball)
4. Eine Rekombination auf mathematischer Ebene: Bedeutungsvektor "Katze" kombiniert mit Bedeutungsvektor "Ball".

**Was lernt man?**

- Wie das Modell Konzepte "isoliert"
- Wie Konzepte interagieren
- Dass die Summe nicht gleich den Teilen ist
- Wo die Grenzen der Zerlegbarkeit liegen

### Partial Elimination: Dimensionen ausschalten

Semantische Vektoren haben viele Dimensionen (Stable Diffusion 3.5 large mit dem t5xxl-Sprachmodul löst Bedeutungen in 4096 Dimensionen auf). Jede Dimension kodiert irgendeine Art von "Bedeutung" – aber welche?

Partial Elimination **schaltet Teile der Dimensionen aus** und zeigt, was passiert:

1. Normales Bild (alle Dimensionen)
2. Bild mit erster Hälfte der Dimensionen entfernt/durch Durchschnitt ersetzt/Wert invertiert/durch Zufallswert ersetzt
3. Bild mit zweiter Hälfte der Dimensionen entfernt/durch Durchschnitt ersetzt/Wert invertiert/durch Zufallswert ersetzt

**Was lernt man?**

- Welche Aspekte (Farben, Objekte, Stimmungen) in welchen Dimensionen getriggert werden
- Dass Bedeutung über den Vektorraum verteilt kodiert ist
- Dass Teilinformationen zu "kaputten" Bildern führen, manchmal aber auch zu überraschenden neuen Bildern
- Die innere Struktur von AI ihre eigenen Logiken, auch wenn wir sie nicht vollständig verstehen

### Pädagogischer Wert der experimentellen Workflows

Diese Workflows sind **nicht unbedingt für die Bildproduktion** gedacht. Sie sind für das **Verstehen**.

Sie beantworten keine Fragen endgültig. Sie erzeugen neue Fragen:
- Was bedeutet "Verstehen" bei einer Maschine?
- Wie kann Bedeutung in Zahlen kodiert sein?
- Was geht verloren, wenn wir Sprache in Vektoren übersetzen?
- Ist das überhaupt noch "mein" Bild?

Diese Fragen sind philosophisch. Sie haben keine einfachen Antworten. Aber sie können **erfahren** werden, durch Experimentieren mit den Workflows.

### Forschung vs. Produktion

AI4ArtsEd unterscheidet zwischen **Regel-Workflows** und **Forschungs-Workflows**:

| Regel-Workflows | Forschungs-Workflows |
|-----------------|----------------------|
| WAS/WIE-Prinzip | Direkte Vektor-Manipulation |
| LLM verarbeitet | Kein LLM-Schritt |
| Prompt wird transformiert | Prompt wird direkt verwendet |
| Für kreative Arbeit | Für Verständnis und Exploration |

Beide haben ihren Platz. Die Forschungs-Workflows sind für fortgeschrittene Nutzer:innen, die tiefer graben wollen.

---

## 7. Die Rolle der Pädagog:innen

### Kein Selbstläufer

AI4ArtsEd ist **kein Selbstbedienungs-Tool**. Die Plattform ist für den Einsatz in begleiteten Workshops konzipiert. Pädagog:innen spielen eine zentrale Rolle – nicht als technische Anleiter:innen, sondern als **Reflexionsbegleiter:innen**.

### Was die Plattform nicht leistet

Die Plattform kann:
- Prozesse sichtbar machen
- Eingriffsmöglichkeiten bieten
- Vergleiche ermöglichen
- Experimente unterstützen

Die Plattform kann **nicht**:
- Reflexion erzwingen
- Kritisches Denken automatisch auslösen
- Die richtigen Fragen stellen
- Erkenntnisse in Sprache fassen

Hier kommen die Pädagog:innen ins Spiel.

### Aufgaben der Begleitung

**1. Fragen stellen**

- "Was ist hier passiert?"
- "Warum sieht das anders aus als erwartet?"
- "Was hättest du anders machen können?"
- "Woran erkennst du den Unterschied?"

Die Plattform zeigt. Pädagog:innen fragen.

**2. Reflexion anregen**

Nicht jede Erfahrung wird automatisch zur Erkenntnis. Pädagog:innen helfen, das Gesehene einzuordnen:
- Verbindungen zu anderen Kontexten herstellen
- Abstraktion ermöglichen
- Überraschungen produktiv machen

**3. Rahmen setzen**

- Aufgaben formulieren, die zum Experimentieren einladen
- Zeiträume strukturieren (Exploration vs. Reflexion vs. Präsentation)
- Gruppen zusammenstellen für Vergleich und Diskussion

**4. Nicht zu viel erklären**

Paradoxerweise ist es oft wichtig, **nicht** zu erklären, wie etwas funktioniert. Der Wert liegt im eigenen Entdecken. Pädagog:innen müssen aushalten, dass Fragen offen bleiben.

### Pädagogische Modelle (in Entwicklung)

Die Frage, wie Workshops mit AI4ArtsEd optimal gestaltet werden, ist Teil des Forschungsprojekts. Verschiedene pädagogische Modelle werden derzeit empirisch erprobt:

- Wie viel Struktur brauchen verschiedene Altersgruppen?
- Welche Aufgabenformate fördern kritisches Erkunden?
- Wie kann Reflexion in Gruppen organisiert werden?
- Welche Rolle spielt die Vorerfahrung mit KI?

Die Ergebnisse dieser Forschung werden aufbereitet und auf der Plattform zur Verfügung gestellt – als **Handreichungen für Pädagog:innen**, die AI4ArtsEd in ihrer Arbeit einsetzen wollen.

### Ohne Begleitung

Kann AI4ArtsEd auch ohne pädagogische Begleitung genutzt werden? Ja, technisch. Aber der pädagogische Mehrwert entfaltet sich in der begleiteten Reflexion. Die Plattform ist ein Werkzeug. Wie jedes Werkzeug braucht sie kompetente Anwendung.

---

## Zusammenfassung: AI4ArtsEd als pädagogisches Konzept

### Die sechs Prinzipien

AI4ArtsEd basiert auf sechs zusammenhängenden Prinzipien:

| Prinzip | Kernaussage | Pädagogisches Ziel |
|---------|-------------|-------------------|
| **WAS/WIE-Trennung** | Idee und Regeln werden getrennt | Bewusstsein für Gestaltungsentscheidungen |
| **LLM als Co-Akteur** | Das Modell gestaltet mit, nicht nur für | Kritische Reflexion über Autorenschaft |
| **Kritisches Erkunden** | Modelle werden untersucht, nicht nur genutzt | Forschende Haltung gegenüber Technologie |
| **Sichtbare Verarbeitung** | Jeder Schritt ist beobachtbar und veränderbar | Entmystifizierung und Kontrolle |
| **Zirkularität** | Ergebnisse sind Ausgangspunkte | Prozessorientierung und Eigenständigkeit |
| **Pädagogische Begleitung** | Die Plattform braucht Reflexionsbegleitung | Fragen stellen, nicht nur zeigen |

### Was AI4ArtsEd nicht ist

**Kein Produktionswerkzeug**

AI4ArtsEd ist nicht optimiert für schnelle, effiziente Bildproduktion. Es gibt keine "One-Click"-Lösungen. Der Umweg über die sichtbare Pipeline ist gewollt.

**Keine Prompt-Engineering-Schule**

Das Ziel ist nicht, "bessere Prompts" zu schreiben. Das Ziel ist, den Prozess des Promptens zu verstehen und kritisch zu hinterfragen.

**Kein KI-Verherrlicher**

Die Plattform zeigt nicht nur, was KI kann. Sie zeigt auch, was sie nicht kann. Die Faszination wird begleitet von kritischer Distanz.

**Keine fertige Antwort**

AI4ArtsEd beantwortet nicht die Frage "Wie nutze ich KI richtig?". Es ermöglicht, diese Frage selbst zu erforschen.

### Was AI4ArtsEd ist

**Eine Experimentierplattform**

Ein Ort, an dem Hypothesen aufgestellt und getestet werden können. An dem Fehler lehrreich sind. An dem Neugier belohnt wird.

**Ein pädagogisches Werkzeug**

Entwickelt für die kulturelle Bildung. Geeignet für Workshop-Kontexte. Begleitet von Lehrpersonen, die Reflexion anregen.

**Eine kritische Intervention**

Ein Gegenentwurf zur "magischen KI". Eine Sichtbarmachung dessen, was normalerweise verborgen bleibt. Ein Werkzeug zur Emanzipation.

### Offene Fragen

Das Konzept wirft Fragen auf, die nicht abschließend beantwortet sind:

- Wie viel Sichtbarkeit ist für welches Alter angemessen?
- Ab wann wird Komplexität überwältigend statt lehrreich?
- Wie misst man den Lernerfolg bei kritischem Erkunden?
- Welche neuen Formen von "Kreativität" entstehen durch Co-Akteurschaft?
- Wie verändert sich das Konzept, wenn sich die Technologie verändert?

Diese Fragen sind Teil des Forschungsprozesses. AI4ArtsEd ist selbst ein Experiment.

---

## Kontext und Förderung

AI4ArtsEd ist ein Forschungs- und Entwicklungsprojekt im Bereich der kulturellen Bildung. Es wurde ursprünglich gefördert durch das Bundesministerium für Bildung und Forschung (BMBF) und wird seit der Ministeriumsreform durch das Bundesministerium für Bildung, Familie, Senioren, Frauen und Jugend (BMBFSFJ) weitergeführt. Entwicklungspartner ist die Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU).

Die Plattform wird in Workshops mit Kindern und Jugendlichen erprobt und auf Basis der Erfahrungen weiterentwickelt. Die pädagogischen Prinzipien werden kontinuierlich reflektiert und angepasst. Die empirische Evaluation der Workshop-Modelle fließt zurück in die Entwicklung von Handreichungen für Pädagog:innen.

---

*Dieses Konzeptpapier dokumentiert den Stand Januar 2026. Die Plattform und ihr pädagogisches Konzept entwickeln sich weiter.*

