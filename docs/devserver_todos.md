# DevServer Implementation TODOs
**Last Updated:** 2026-02-02
**Context:** Current priorities and active TODOs

---

## ğŸ”´ CRITICAL REFACTORING: Proxy-Chunk-Pattern eliminieren

**Status:** ğŸ”´ **ARCHITEKTUR-VERLETZUNG** - Refactoring erforderlich
**Datum:** 2026-02-02
**Priority:** HIGH (blockiert saubere Backend-Integrationen)
**Dokumentation:** `docs/ARCHITECTURE_VIOLATION_ProxyChunkPattern.md`

### Problem

Das `output_image.json` Proxy-Chunk-Pattern verletzt die 3-Ebenen-Architektur:

- **Soll:** Pipeline entscheidet welche Chunks ausgefÃ¼hrt werden
- **Ist:** Config.OUTPUT_CHUNK entscheidet, Proxy-Chunk routet zu anderem Chunk

### Betroffene Dateien

- `single_text_media_generation.json` Pipeline
- `output_image.json` Proxy-Chunk
- 17 Output-Configs die das Pattern nutzen

### LÃ¶sung

Pipeline sollte `{{OUTPUT_CHUNK}}` direkt in `chunks` Array verwenden - kein Proxy nÃ¶tig.

**Referenz-Implementierung:** `dual_text_media_generation` Pipeline (HeartMuLa) zeigt das korrekte Pattern.

---

## âœ… GELÃ–ST: TrÃ¤shy Ruheposition auÃŸerhalb Viewport

**Status:** âœ… **GELÃ–ST** - Session 147
**Datum:** 2026-01-29

### Problem (gelÃ¶st)
TrÃ¤shy (ChatOverlay) saÃŸ in seiner Ruheposition (collapsed state) halb auÃŸerhalb des Browserfensters.

### LÃ¶sung
`ChatOverlay.vue`: Positionierungslogik komplett Ã¼berarbeitet:
- Prozentuale Positionierung durch Pixel-basierte Positionierung mit Clamping ersetzt
- Icon-GrÃ¶ÃŸe (100px max) wird jetzt berÃ¼cksichtigt
- Sowohl collapsed als auch expanded State werden innerhalb des Viewports gehalten
- `minRight/maxRight` und `minBottom/maxBottom` Grenzen eingefÃ¼hrt

---

## ğŸ”´ CRITICAL UX: Canvas Execution Feedback

**Status:** ğŸ“‹ **TODO** - User erlebt 5 Minuten Stillstand ohne jegliche RÃ¼ckmeldung
**Datum:** 2026-01-26 (Session 136)
**Priority:** HIGH (Usability-Blocker)

### Problem

Bei komplexen Canvas Workflows starren User 5+ Minuten auf den Bildschirm ohne jegliches Feedback:
- Keine Progress-Anzeige
- Keine Statusmeldungen
- Keine Bubble-Animation WÃ„HREND der Generierung (nur danach)
- Terminal zeigt Debug-Output, aber Frontend ist stumm

### Anforderungen

IRGENDEINE Form der RÃ¼ckmeldung implementieren:

1. **Minimum Viable**: Spinner oder "Generating..." Text wÃ¤hrend Execution
2. **Besser**: Progress-Anzeige pro Node (Node X von Y wird verarbeitet)
3. **Ideal**: SSE-Stream mit Live-Updates vom Backend
   - Welcher Node wird gerade ausgefÃ¼hrt
   - Aktueller Stage (Interception/Translation/Generation)
   - Estimated time remaining (optional)

### Technische Optionen

**Option A: Polling (einfach)**
- Frontend pollt `/api/canvas/status/{run_id}` alle 2 Sekunden
- Backend trackt aktuellen Node in Session/Memory
- Pro: Einfach zu implementieren
- Con: Nicht real-time, zusÃ¤tzliche Requests

**Option B: SSE Stream (sauber)**
- Backend sendet Events: `node_started`, `node_completed`, `error`
- Frontend zeigt Live-Progress
- Pro: Real-time, elegant
- Con: Mehr Aufwand, SSE-Infrastruktur nÃ¶tig

**Option C: WebSocket (overkill)**
- Bidirektionale Kommunikation
- Pro: Maximal flexibel
- Con: UnnÃ¶tig komplex fÃ¼r diesen Use Case

### Betroffene Dateien

**Backend:**
- `devserver/my_app/routes/canvas_routes.py` - Execution mit Progress-Tracking

**Frontend:**
- `public/ai4artsed-frontend/src/stores/canvas.ts` - Progress-State
- `public/ai4artsed-frontend/src/views/canvas_workflow.vue` - Progress-UI

### User-Zitat

> "User starren jetzt bei komplexem run fÃ¼r 5 Minuten auf Bildschirm ohne Aktion, ohne Feedback."
> "Es wÃ¤re ja nett zumindest einen gefilterten Stream vom Debug-Output zu sehen."

---

## ğŸ”´ PRIORITY: Safety-Architektur Refactoring

**Status:** ğŸ“‹ **GEPLANT** - Detaillierter Plan vorhanden
**Datum:** 2026-01-26
**Priority:** HIGH (SicherheitslÃ¼cke + Architektur-Inkonsistenz)

**Handover-Dokument:** `docs/HANDOVER_SAFETY_REFACTORING.md`
**Detaillierter Plan:** `~/.claude/plans/wise-napping-metcalfe.md`

### Gefundene Probleme

1. **KRITISCH: context_prompt nicht geprÃ¼ft** - User-editierbarer Meta-Prompt wird nirgends safety-geprÃ¼ft
2. **Namens-Inkonsistenz**: `/interception` macht Stage 1 + Stage 2 (nicht nur Interception)
3. **Code-Duplikation**: Stage 1 Safety in 4 Endpoints embedded statt zentral
4. **Frontend Bug**: MediaInputBox ignoriert 'blocked' SSE Events

### Ziel-Architektur

```
NACHHER (sauber getrennt):
â”œâ”€â”€ /pipeline/safety            â†’ NUR Stage 1 + context_prompt Support
â”œâ”€â”€ /pipeline/stage2            â†’ NUR Stage 2 (kein embedded Safety)
â”œâ”€â”€ /pipeline/generation        â†’ Stage 3 + Stage 4 + context_prompt
â””â”€â”€ /pipeline/interception      â†’ DEPRECATED
```

### Betroffene Dateien

**Backend:**
- `devserver/my_app/routes/schema_pipeline_routes.py` (5 Stellen)

**Frontend:**
- `public/ai4artsed-frontend/src/views/text_transformation.vue`

### NÃ¤chste Schritte

1. Handover lesen: `docs/HANDOVER_SAFETY_REFACTORING.md`
2. Plan lesen: `cat ~/.claude/plans/wise-napping-metcalfe.md`
3. Backend implementieren (Teil 1-4)
4. Frontend implementieren (Teil 5)
5. Verifizieren (4 Tests im Plan)

**GeschÃ¤tzter Aufwand:** 3-4 Stunden

---

## ğŸ”´ CRITICAL REFACTORING: Output-Chunks als AusfÃ¼hrungseinheiten

**Status:** ğŸ”´ **ARCHITEKTUR-VERLETZUNG** - Output-Chunks wurden zu Metadaten-Containern degradiert
**Datum:** 2026-02-02
**Priority:** HIGH (blockiert neue Backend-Integrationen wie HeartMuLa)

### Das Problem

Output-Chunks sollten die **komplette AusfÃ¼hrung** Ã¼bernehmen und ein fertiges Produkt liefern. Stattdessen:

1. **Chunks wurden zu reinen Metadaten-Containern** - enthalten nur `input_mappings`, `meta`, etc.
2. **Zentraler Code Ã¼berladen** - `backend_router.py` hat jetzt `_process_diffusers_chunk()`, `_process_heartmula_chunk()`, etc.
3. **Unmaintainbar** - FÃ¼r jedes neue Backend muss zentraler Code geÃ¤ndert werden

### Soll-Zustand (UrsprÃ¼ngliche Architektur)

Output-Chunks enthalten **ausfÃ¼hrbaren Code** oder **vollstÃ¤ndige Konfiguration**:

| Chunk-Typ | AusfÃ¼hrungs-Config | Beispiel |
|-----------|-------------------|----------|
| ComfyUI | `workflow` | Komplettes ComfyUI-Workflow JSON |
| API | `api_config` | endpoint, headers, request_body |
| Diffusers | `diffusers_config` | model_id, pipeline_class |
| **HeartMuLa** | **FEHLT** | Sollte `heartmula_config` haben |

### Ist-Zustand (Architektur-Verletzung)

- **Diffusers-Chunks** haben zwar `diffusers_config`, aber die AusfÃ¼hrungslogik ist in `backend_router.py:_process_diffusers_chunk()`
- **HeartMuLa-Chunk** hat NUR Metadaten - keine AusfÃ¼hrungskonfiguration
- **Neue Backends** erfordern Ã„nderungen am zentralen `backend_router.py`

### Konsequenz

Diese Praxis bringt das komplette Development durcheinander:
- Entwickler suchen Logik im Chunk, finden sie aber im Router
- Debugging wird schwieriger (Logik verstreut)
- Neue Backends kÃ¶nnen nicht "einfach einen Chunk hinzufÃ¼gen"

### Betroffene Dateien

**Zentral (Ã¼berladen):**
- `devserver/schemas/engine/backend_router.py` - EnthÃ¤lt Backend-spezifische Logik die in Chunks gehÃ¶rt

**Chunks (unvollstÃ¤ndig):**
- `devserver/schemas/chunks/output_music_heartmula.json` - Nur Metadaten, keine AusfÃ¼hrungskonfiguration
- `devserver/schemas/chunks/output_image_*_diffusers.json` - Hat Config, aber Logik im Router

### TODO: Diffusers refactoren

Die Diffusers-Chunks haben `diffusers_config`, aber die AusfÃ¼hrungslogik (`_process_diffusers_chunk()`) gehÃ¶rt eigentlich IN den Chunk oder in ein Chunk-spezifisches Modul - nicht in den zentralen Router.

### TODO: HeartMuLa korrekt implementieren

HeartMuLa-Chunk braucht eine vollstÃ¤ndige `heartmula_config` die definiert WIE heartmula aufgerufen wird, analog zu `diffusers_config` oder `api_config`.

---

## ğŸ”§ Chck for Need for REFACTORING: Prinzip der Pipeline-Autonomie
Was in den Ã¼ber hundert
    Session ggf. etwas verwÃ¤ssert wurde ich meine Idee der "Binnen-Orchestrierung" der Pipelines in ihrer DomÃ¤ne. Ich habe sie wie ausfÃ¼hrenden Code gedacht, der
     eben diese Interveption-Aufgabe erledigt (input -> komplexer Prozess -> einfacher Output). In dieser Logik wÃ¼rde die Pipeline eben auch rekursive
    Chunk-Aufrufe einfach selbst orchestrieren.

    Ich denke das passt sehr gut zu unserem Paradigmenwechsel vom Backend-Orchestrator zur objektorientierten Frontend/VUE-Prozessinitiierung.

Konkret heiÃŸt das fÃ¼r mich, der ich die Codebasis nicht vollstÃ¤ndig Ã¼berblicke: sind ggf in den schema-/pipeline- und chunkbezogenen py-Codefiles ggf. Funktionen absorbiert, die eigentlich zwischen Pipelines und "ihren" Chunks hÃ¤tten realisiert werden sollen?


## ğŸ¯ CANVAS: Evaluation Nodes - Conditional Execution (Phase 3b) - DONE

**Status:** ğŸ”´ **BLOCKED** - UI works, execution logic missing
**Priority:** HIGH (User-facing feature incomplete)
**Session:** 134
**Estimated Effort:** 2-3 hours

### Context

Evaluation nodes are implemented with 3 separate text outputs (Passthrough, Commented, Commentary), but conditional execution is not yet implemented.

**Current Behavior:**
- âœ… UI works: 3 output connectors (P, C, â†’)
- âœ… Backend generates 3 text outputs
- âŒ ALL paths execute (no branching logic)

**Expected Behavior:**
- Only active path (P or C) executes downstream
- Commentary path (â†’) ALWAYS executes
- Based on binary evaluation result

### Technical Requirements

**1. Connection Label Storage**
```typescript
// public/.../types/canvas.ts
interface CanvasConnection {
  sourceId: string
  targetId: string
  label?: 'passthrough' | 'commented' | 'commentary'  // NEW
  active?: boolean  // NEW - Set during execution
}
```

**2. Active Path Marking (Backend)**
```python
# devserver/.../canvas_routes.py
# After evaluation execution
active_path = 'passthrough' if binary_result else 'commented'

# Mark active connections
for conn in connections:
    if conn.sourceId == evaluation_node_id:
        if conn.label == active_path or conn.label == 'commentary':
            conn['active'] = True
        else:
            conn['active'] = False
```

**3. Conditional Execution**
```python
# In execution loop
for node_id in execution_order:
    # Check if all incoming connections are active
    incoming_conns = [c for c in connections if c.targetId == node_id]
    if incoming_conns:
        all_active = all(conn.get('active', True) for conn in incoming_conns)
        if not all_active:
            logger.info(f"[Canvas] Skipping {node_id} (inactive path)")
            continue

    # Execute node
    execute_node(node_id)
```

### Files to Modify

1. `public/ai4artsed-frontend/src/types/canvas.ts`
   - Add `label` and `active` to CanvasConnection

2. `devserver/my_app/routes/canvas_routes.py`
   - Store connection labels in workflow
   - Mark active connections after evaluation
   - Skip nodes on inactive paths

3. `public/ai4artsed-frontend/src/stores/canvasStore.ts` (if exists)
   - Store connection labels when creating connections

### Testing Checklist

- [ ] Evaluation with binary=true â†’ only Passthrough path executes
- [ ] Evaluation with binary=false â†’ only Commented path executes
- [ ] Commentary path ALWAYS executes (regardless of binary)
- [ ] Loop workflow: Input â†’ Interception â†’ Eval â†’ Loop Controller â†’ Interception
- [ ] Multiple evaluations in series (Fairness â†’ Creativity)

### Related Docs

- `docs/ARCHITECTURE_CANVAS_EVALUATION_NODES.md` - Full architecture
- `docs/HANDOVER_SESSION_134.md` - Implementation details

---

## ğŸ”„ CANVAS: Loop Controller Node (Phase 4) - DONE

**Status:** ğŸ“‹ **PLANNED** - Depends on Phase 3b
**Priority:** MEDIUM (After conditional execution)
**Estimated Effort:** 3-4 hours

### Purpose

Enable feedback loops with max iteration limits for iterative content refinement.

### Features

- Max iterations counter (default: 3)
- Current iteration tracking
- Feedback target node selection (dropdown)
- Termination conditions:
  - `max_iterations` reached
  - `evaluation_passed` (binary=true)
  - `both` (either condition)

### UI Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”„ LOOP CONTROLLER   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Max Iterations: [3]  â”‚
â”‚ Feedback to: [â–¼]     â”‚ â† Dropdown of canvas nodes
â”‚ Terminate: [Both â–¼]  â”‚
â”‚                      â”‚
â”‚ Current: 0 / 3       â”‚ â† Shows during execution
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Workflow

```
Input â†’ Interception â†’ Generation â†’ Quality Eval
         â†‘                              â†“ (Commented path)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Loop Controller â”€â”€â”€â”€â”˜
                    (max 3 iterations)
```

**Behavior:**
1. Quality Eval fails (score < 7) â†’ Commented output
2. Loop Controller receives Commented text
3. Increment iteration counter (1/3)
4. Check termination: Not reached â†’ continue
5. Route to Interception with feedback
6. Repeat until: Quality passes OR max iterations reached

### Technical Implementation

**Node Type:**
```typescript
type: 'loop_controller'
maxIterations: number
currentIteration: number  // Managed by backend
feedbackTargetId: string  // Node ID to loop back to
terminationCondition: 'max_iterations' | 'evaluation_passed' | 'both'
```

**Backend Logic:**
```python
elif node_type == 'loop_controller':
    # Get iteration counter from state
    iteration = loop_state.get(node_id, {}).get('iteration', 0)
    max_iter = node.get('maxIterations', 3)

    # Check termination
    should_terminate = False

    if node.get('terminationCondition') == 'max_iterations':
        should_terminate = iteration >= max_iter
    elif node.get('terminationCondition') == 'evaluation_passed':
        # Check if previous eval passed
        prev_eval_binary = get_previous_eval_binary(node_id)
        should_terminate = prev_eval_binary
    elif node.get('terminationCondition') == 'both':
        should_terminate = iteration >= max_iter or get_previous_eval_binary(node_id)

    if should_terminate:
        # Exit loop - continue to next node
        logger.info(f"[Loop] Terminating after {iteration} iterations")
        results[node_id] = {'type': 'loop_exit', 'output': input_text}
    else:
        # Continue loop - re-queue feedback target
        iteration += 1
        loop_state[node_id] = {'iteration': iteration}
        logger.info(f"[Loop] Iteration {iteration}/{max_iter}")

        # Re-queue feedback target for execution
        feedback_target = node.get('feedbackTargetId')
        execution_queue.append(feedback_target)

        results[node_id] = {'type': 'loop_continue', 'output': input_text, 'iteration': iteration}
```

### Challenges

**Re-queueing Nodes:**
- Current execution uses topological sort (DAG)
- Loops create cycles â†’ need execution queue instead
- Or: Special handling for loop edges (ignore in topo sort)

**State Management:**
- Iteration counter must persist across node executions
- Per-loop state dict: `{loop_controller_id: {iteration: N}}`

**Infinite Loop Prevention:**
- Hard limit: Max 10 iterations (configurable)
- Timeout: Max execution time per workflow

### Files to Modify

1. `public/.../types/canvas.ts` - loop_controller type
2. `public/.../StageModule.vue` - Loop controller UI
3. `public/.../ModulePalette.vue` - Add to palette
4. `devserver/.../canvas_routes.py` - Loop execution logic

---

## ğŸ”§ REFACTORING: Provider Routing ohne PrÃ¤fix-Parsing

**Status:** ğŸ“‹ **PLANNED** - Aktuelle LÃ¶sung funktioniert, aber fragil
**Reported:** 2026-01-23
**Priority:** MEDIUM (Verbesserung, kein Blocker)

### Problem

Die aktuelle Provider-Detection in `prompt_interception_engine.py` basiert auf Model-String-PrÃ¤fixen:

```python
# Aktuell (fragil)
if model.startswith("openrouter/"):
    return call_openrouter(model.removeprefix("openrouter/"))
elif model.startswith("anthropic/"):
    return call_anthropic(model)
```

**Schwachstellen:**
1. **Doppelte Wahrheit**: `EXTERNAL_LLM_PROVIDER` sagt "openrouter", aber Routing prÃ¼ft Model-String
2. **Leicht zu vergessen**: Commit 6eec19d entfernte versehentlich `openrouter/` PrÃ¤fixe
3. **UnÃ¼bersichtlich**: `openrouter/anthropic/claude-sonnet-4.5` ist redundant

### Saubere LÃ¶sung

Routing basierend auf `EXTERNAL_LLM_PROVIDER` (Single Source of Truth):

```python
# Nachher (robust)
provider = config.EXTERNAL_LLM_PROVIDER
if provider == "openrouter":
    return call_openrouter(model)  # model = "anthropic/claude-sonnet-4.5"
elif provider == "anthropic":
    return call_anthropic(model)   # model = "anthropic/claude-3-5-sonnet-latest"
```

### Vorteile

- Model-Namen bleiben sauber (ohne `openrouter/` PrÃ¤fix)
- Provider-Einstellung bestimmt Routing
- Weniger fehleranfÃ¤llig bei Config-Ã„nderungen
- `HARDWARE_MATRIX` Presets brauchen keine redundanten PrÃ¤fixe

### Betroffene Dateien

1. `devserver/schemas/engine/prompt_interception_engine.py` - Routing-Logik
2. `devserver/my_app/routes/settings_routes.py` - HARDWARE_MATRIX (PrÃ¤fixe entfernen)
3. Ggf. weitere Provider-Detection in anderen Dateien

### Aufwand

~2-3 Stunden (inkl. Testing)

---

## âœ… COMPLETED (2026-01-17): Unified Export Across Lab Endpoints

**Status:** âœ… **COMPLETE** - All backends tested and working
**Commit:** `7f07197`

### What Was Fixed

**Problem:** Export function BROKEN - entities scattered across multiple folders
- `/interception` created `run_xxx/` with input, safety, interception
- `/generation` created `run_yyy/` with output_image
- Result: Incomplete exports, no unified research data

**Solution:** Frontend passes `run_id` from `/interception` to `/generation`
- Backend loads existing Recorder via `load_recorder()`
- All entities saved to ONE unified folder

### Additional Fixes

**Multi-Backend Image Saving:**
- âŒ Before: Only SD3.5 (`swarmui_generated`) saved images
- âœ… After: ALL backends work:
  - SD3.5: Unchanged (via SwarmUI API)
  - QWEN/FLUX2: Read from `filesystem_path`
  - Gemini/GPT-Image: Decode from base64

**Files Modified:**
- `schema_pipeline_routes.py`: `load_recorder` import, filesystem_path + base64 handling
- `text_transformation.vue`: Pass `run_id` to /generation

### Architectural Cleanup âœ… COMPLETE (2026-01-17)

**Completed:** Eliminated `image_workflow` type - all image models now use `media_type: "image"`
- Changed `output_image_qwen.json`: `image_workflow` â†’ `image`
- Changed `output_image_flux2.json`: `image_workflow` â†’ `image`
- Simplified `backend_router.py` line 749

---

## ğŸš§ IN PROGRESS (Session 98 - 2025-12-13)

### Two Open Issues - partial_elimination
**Status:** âš ï¸ **INCOMPLETE** - Two related issues need resolution
**Priority:** HIGH (composite important, routing required)
**Sessions:** 97 (abandoned), 98 (redesign + partial fixes)

**âš ï¸ READ THIS FIRST:** `docs/HANDOVER_Session_98_Two_Open_Issues.md`

### Issue #1: Composite Image Not Created (Backend)

**Problem:** Backend doesn't create composite image (code was reverted in Session 97)

**Solution:** Re-add 36 lines after `schema_pipeline_routes.py:2016`
```python
if len(media_files) > 1:
    composite_data = recorder.create_composite_image(...)
    recorder.save_entity(entity_type='output_image_composite', ...)
```

**Effort:** 5 minutes

### Issue #2: Vue Not in /execute/ Path (Frontend)

**Problem:** `partial_elimination.vue` in wrong location
- Current: `src/views/partial_elimination.vue`
- Expected: `src/views/execute/partial_elimination.vue` (or similar)
- Missing: Stage2 proxy config for routing

**Solution:**
1. Investigate existing `/execute/` routing pattern
2. Create proxy config (if needed)
3. Move Vue file to correct location
4. Update router

**Effort:** 30-60 minutes

### What Works Already âœ…

- âœ… Frontend redesigned (design standards compliant)
- âœ… Dual-fetch logic (individuals + composite)
- âœ… New backend endpoint: `/api/pipeline/<run_id>/file/<filename>`
- âœ… Flexible 3-4 image grid layout
- âœ… All standard actions functional

**See:** Full details in `docs/HANDOVER_Session_98_Two_Open_Issues.md`

---

## âœ… COMPLETED (Session 91 - 2025-12-09)

### Model Availability Check - API-Based
**Status:** âœ… **COMPLETED** - All models correctly detected, frontend filters by availability
**Session:** 91 (2025-12-09)
**Duration:** ~95 minutes

**Implemented:**
- Backend: ModelAvailabilityService queries ComfyUI `/object_info` API
- Endpoint: `GET /api/models/availability` returns availability map
- Frontend: text_transformation.vue filters configs by availability
- Result: wan22_video and stableaudio_open correctly shown (Session 90 failed at this)

---

## ğŸ“‹ FOLLOW-UP (Session 91+)

### Automate configsByCategory in text_transformation.vue
**Status:** ğŸ“‹ **PLANNED** - After Session 91 success
**Priority:** MEDIUM
**Context:** User requested this AFTER model availability check working

**Current Problem:**
`text_transformation.vue` has hardcoded model lists:
```typescript
const configsByCategory = {
  image: [
    { id: 'flux2', label: 'Flux 2', ... },  // Hardcoded
    { id: 'sd35_large', label: 'SD 3.5', ... },  // Hardcoded
  ],
  video: [...],  // Hardcoded
  sound: [...]   // Hardcoded
}
```

**Desired Behavior:**
- Fetch all output configs from backend dynamically
- Categorize automatically by `media_preferences.default_output` (image/video/sound)
- Apply availability filter (from Session 91)
- New models appear automatically without Vue changes

**Implementation Plan:**

1. **Backend: Extend `/api/models/availability` endpoint** (or create new endpoint)
   - Return not just `{config_id: boolean}` but full metadata:
     ```json
     {
       "configs": [
         {
           "id": "flux2",
           "name": {"en": "Flux 2", "de": "Flux 2"},
           "media_type": "image",
           "logo": "/logos/flux_logo.png",
           "color": "#FF6B35",
           "available": true
         },
         ...
       ]
     }
     ```
   - Use existing `/pipeline_configs_with_properties` as reference
   - Filter to only Stage 4 output configs

2. **Frontend: Replace hardcoded configsByCategory**
   - Fetch configs on mount
   - Group by `media_type` (image/video/sound)
   - Apply availability filter
   - Map to existing Config interface format

3. **Benefits:**
   - Add new model in backend â†’ automatically appears in UI
   - Consistent with Phase 1 property-based config loading
   - Logo, color, name changes centralized in backend configs

**Files to Modify:**
- `devserver/my_app/routes/config_routes.py` (extend /api/models/availability or new endpoint)
- `public/ai4artsed-frontend/src/views/text_transformation.vue` (replace configsByCategory)
- `public/ai4artsed-frontend/src/services/api.ts` (add interface for extended response)

**Testing:**
- All current configs still appear correctly
- Add new test config â†’ appears without Vue changes
- Availability filter still works
- Logo and colors render correctly

---

## âœ… FIXED BUG (Session 135 - 2026-01-24)

### Prompt Optimization META-Instruction
**Status:** âœ… **FIXED** - Session 135
**Priority:** HIGH
**Reported:** 2025-11-26 | **Fixed:** 2026-01-24

**Problem:**
Die `prompt_optimization` META-Instruction in `instruction_selector.py` hatte hardcodierte kulturelle Mappings ("qiyun shengdong â†’ dynamic brushstrokes") und ein image-spezifisches Output-Format.

**Root Cause:**
Die META-Instruction versuchte, kreative Interception-Outputs in fixierte Bildanweisungen zu hardcodieren. Die eigentlichen Regeln stehen bereits in den Output-Chunk `optimization_instruction` Feldern.

**Fix:**
Vereinfachte `prompt_optimization` zu einer simplen "Wende Context-Regeln an" Instruction:
```python
"prompt_optimization": {
    "description": "Apply media-specific optimization rules from Context",
    "default": """Transform the Input according to the rules in Context.

The Context contains media-specific transformation rules.
Apply these rules precisely to the Input.
Preserve the language of the Input.

Output ONLY the transformed result.
NO meta-commentary, NO headers, NO formatting."""
}
```

**Files Changed:**
- `devserver/schemas/engine/instruction_selector.py` (Zeilen 27-37)

**See:** `docs/HANDOVER_2026-01-24_Session134_OptimizationProblem.md` fÃ¼r Details

---

## ğŸ”„ CURRENT WORK (Session 59)

### Stage 1-3 Translation Refactoring - **PLANNED**
**Status:** ğŸ“‹ **READY TO IMPLEMENT** - Architecture corrected, clean develop branch
**Session:** 59 (2025-11-21)
**Priority:** HIGH (corrects flawed Session 56-58 mega-prompt architecture)

**The Problem:**
Session 56-58 planned to "eliminate Stage 3" by merging it into Stage 2 as a "mega-prompt" with built-in safety. This was a **pedagogical error** - users need to edit AFTER optimization but BEFORE final safety check. The architecture needs correction.

**The Correction:**
```
Stage 1: Safety ONLY (NO translation, bilingual DE/EN)
Stage 2: Interception + Optimization (in original language)
  â†’ USER CAN EDIT HERE!
Stage 3: Translation (DEâ†’EN) + Safety
Stage 4: Media Generation
```

**Implementation Tasks:**

1. **Stage 1: Remove Translation** (HIGH priority)
   - Create `/devserver/schemas/configs/pre_interception/gpt_oss_safety_only_bilingual.json`
   - Add `execute_stage1_safety_only_bilingual()` to `stage_orchestrator.py`
   - Update `/stage2` endpoint (line 252) to use safety-only function
   - Update `/execute` endpoint (line 541) to use safety-only function
   - Test: German input should NOT be translated in Stage 1

2. **Stage 2: Add Media Optimization** (MEDIUM priority)
   - Option A: Create optimization chunks (`optimize_image.json`, `optimize_audio.json`)
   - Option B: Add optimization to `manipulate.json` template
   - Update pipeline configs to include optimization step
   - Test: Output should be optimized for target media type

3. **Stage 3: Add Translation** (HIGH priority)
   - Create `/devserver/schemas/configs/pre_output/translation_de_en_stage3.json`
   - Add `execute_stage3_translation()` to `stage_orchestrator.py`
   - Update Stage 3-4 loop in `schema_pipeline_routes.py` (around line 700-800)
   - Add translation BEFORE safety check
   - Test: German text should be translated before media generation

4. **Frontend: Remove Context Translation** (LOW priority)
   - Check if `Phase2CreativeFlowView.vue` translates context before sending
   - Remove translation if present
   - Test: Frontend sends context in original language

5. **Testing & Validation** (HIGH priority)
   - Test complete flow: DE input â†’ Safety â†’ Interception â†’ Edit â†’ Translation â†’ Safety â†’ Media
   - Test user context rules: "alle mÃ¤use haben ROTEN HUT" should be preserved
   - Test bilingual: Both DE and EN inputs should work
   - Test all safety levels: kids, youth, off

**Files to Create:**
- `devserver/schemas/configs/pre_interception/gpt_oss_safety_only_bilingual.json`
- `devserver/schemas/configs/pre_output/translation_de_en_stage3.json`
- (Optional) `devserver/schemas/chunks/optimize_image.json`

**Files to Modify:**
- `devserver/schemas/engine/stage_orchestrator.py` (add 2 functions)
- `devserver/my_app/routes/schema_pipeline_routes.py` (Stage 1 and Stage 3 calls)
- (Check) `public/ai4artsed-frontend/src/views/Phase2CreativeFlowView.vue`

**Documentation Updated:**
- âœ… ARCHITECTURE PART 01 (Version 2.1) - Reflects correct Stage 1-3 flow
- âœ… DEVELOPMENT_DECISIONS.md (Active Decision 1) - Explains why Session 56-58 was wrong

**Estimated Time:** 3-4 hours
**Complexity:** Medium (clear plan, well-understood changes)

---

## ğŸ”„ PREVIOUS WORK (Session 52)

### Youth Mode & Pipeline Visualization - **IN PROGRESS**
**Status:** ğŸŸ¡ **PARTIAL IMPLEMENTATION** - Core components ready, integration needed
**Session:** 52 (2025-11-20)
**Priority:** MEDIUM (pedagogical feature for ages 13-17)

**What Was Successfully Completed:**
1. âœ… **Admin Configuration System** (`devserver/config.py`)
   - `UI_MODE` setting: "kids" (8-12), "youth" (13-17), "expert" (teachers/devs)
   - `DEFAULT_SAFETY_LEVEL` setting: "kids", "youth", "adult", "off"
   - Expanded SAFETY_NEGATIVE_TERMS with detailed categorization
   - Clear documentation for admins

2. âœ… **Backend Pipeline Visualization Metadata** (`schema_pipeline_routes.py:823-905`)
   - `_get_step_icon()`: Returns emoji for chunk types (ğŸ“, ğŸ¨, ğŸ–¼ï¸)
   - `_get_child_friendly_label()`: Returns 2-3 word labels in DE/EN
   - `_get_pipeline_visualization_metadata()`: Reads pipeline structure from schemas
   - Enhanced `/api/schema/pipeline/execute` response with visualization data

3. âœ… **Frontend PipelineFlowVisualization Component**
   - File: `public/ai4artsed-frontend/src/components/PipelineFlowVisualization.vue` (~550 lines)
   - Horizontal flow: ğŸ’¡ Input â†’ ğŸ“ Understanding â†’ ğŸ¨ Visuals â†’ ğŸ–¼ï¸ Image â†’ [Result]
   - Status indicators: âš™ï¸ (running), âœ“ (complete), âœ— (failed)
   - Responsive: horizontal (desktop), vertical (mobile)
   - Accessibility: high contrast, reduced motion support

4. âœ… **Frontend TypeScript Types** (`api.ts:70-122`)
   - `ExecutionStep`, `PipelineStepDefinition`, `PipelineVisualization` interfaces
   - Extended `PipelineExecuteResponse` with visualization metadata

5. âœ… **i18n Translations** (`i18n.ts:137-141, 276-280`)
   - Pipeline labels in German and English

**What's Broken/Missing:**
1. **ğŸŸ¡ Transform API Visualization** - **ROLLED BACK** due to 500 errors
   - Attempted to extend `/api/schema/pipeline/stage2` with pipeline_visualization
   - Caused AttributeError (needs careful testing)
   - Transform-only configs (dada, bauhaus) never show visualization currently

2. **ğŸŸ¡ UI Mode System Not Wired Up**
   - `UI_MODE` in config.py but not consumed anywhere
   - Need to add uiMode to userPreferences store
   - Need to add UI Mode toggle button in Phase2CreativeFlowView
   - Need conditional rendering: `v-if="uiMode !== 'kids'"`

3. **ğŸŸ¡ Safety Level Not Used**
   - `DEFAULT_SAFETY_LEVEL` defined but system still uses request-level safety_level
   - Need to wire up config value to Stage 3 safety checks

4. **ğŸŸ¡ Visualization Placement Limited**
   - Currently only works in media generation overlay (Phase 3/4)
   - Transform-only workflows never trigger `isGenerating`
   - Need visualization during Transform (Phase 2a) as well

**Architecture Understanding (Critical):**
- **Frontend Phases**: Property Selection â†’ Creative Flow â†’ Transform (2a) â†’ Media Selection (2b) â†’ Generation (3/4)
- **Backend Stages**: All pipelines go through 4 stages (some skip Stage 4 if no output_config)
- **Kids Mode (8-12)**: Simple, separated phases - NO pipeline visualization
- **Youth Mode (13-17)**: Educational flow WITH pipeline visualization - show HOW AI works
- **Expert Mode**: Full debug mode with all metadata

**Next Steps for Implementation:**
1. **Add uiMode to userPreferences store**
   - State: `uiMode` ("kids"/"youth"/"expert")
   - Functions: `setUiMode()`, `cycleUiMode()`
   - Persisted in localStorage

2. **Add UI Mode toggle** (Youth Mode implementation)
   - Button in top bar of Phase2CreativeFlowView
   - Cycles through modes: kids â†’ youth â†’ expert

3. **Extend Transform API** (CAREFULLY! Test incrementally!)
   - Add pipeline_visualization to `/api/schema/pipeline/stage2` response
   - Test thoroughly before deploying
   - Check for attribute errors on `config.pipeline_name`

4. **Show visualization in main layout**
   - After result panel, conditional: `v-if="pipelineVisualization && uiMode !== 'kids'"`
   - During transform AND after completion
   - Separate from media generation overlay

5. **Wire up DEFAULT_SAFETY_LEVEL**
   - Use config.DEFAULT_SAFETY_LEVEL in Stage 3 if no request-level override
   - Ensure backwards compatibility

**Files Modified (Session 52):**
- âœ… `devserver/config.py`: ADMIN section (KEPT after rollback)
- â¸ï¸ `devserver/my_app/routes/schema_pipeline_routes.py`: Transform changes (ROLLED BACK)
- â¸ï¸ `public/ai4artsed-frontend/src/services/api.ts`: TransformResponse (ROLLED BACK)
- â¸ï¸ `public/ai4artsed-frontend/src/stores/userPreferences.ts`: uiMode system (ROLLED BACK)
- â¸ï¸ `public/ai4artsed-frontend/src/views/Phase2CreativeFlowView.vue`: UI toggle (ROLLED BACK)

**Estimated Completion Time:** 4-6 hours
**Complexity:** Medium-High (requires careful Transform API work)

---

## ğŸš¨ CRITICAL BUGS - HIGH PRIORITY

### Stage 3 Negative Prompts Not Passed to Stage 4 - **BUG**
**Status:** ğŸ”´ **CRITICAL BUG** - Stage 3 safety negative prompts are ignored
**Discovered:** 2025-11-20 (Session 53)
**Priority:** HIGH (affects all image generation quality and safety)

**Problem:**
Stage 3 generates appropriate negative prompts based on safety level (kids/youth/off), but these are **never passed to Stage 4** (image generation). This means:
- Safety-appropriate negative prompts are ignored
- All SD3.5 images use only the hardcoded default: `"blurry, bad quality, watermark, text, distorted"`
- Kids/youth safety filters generate comprehensive negative prompts but they're discarded

**Current Behavior:**
1. **safety_level='off'**: Only basic quality negatives applied
2. **safety_level='kids'**: Stage 3 generates `"violence, violent, killing, murder, death, blood, gore, horror, scary, demon, evil, nude, naked, nsfw, sexual, abuse"` â†’ **IGNORED**
3. **safety_level='youth'**: Stage 3 generates `"explicit, hardcore, brutal, pornographic, sexual, nsfw, rape, abuse, self-harm, suicide"` â†’ **IGNORED**

**Root Cause:**
- `schema_pipeline_routes.py:862-867`: Stage 4 execution does not pass `negative_prompt` parameter
- `safety_result['negative_prompt']` from Stage 3 is stored but never used
- `backend_router.py:366` falls back to chunk default when no negative_prompt provided

**Files Involved:**
- `devserver/my_app/routes/schema_pipeline_routes.py:770-867` (Stage 3-4 integration)
- `devserver/schemas/engine/stage_orchestrator.py:477-605` (Stage 3 execution)
- `devserver/schemas/engine/backend_router.py:366` (negative_prompt fallback)
- `devserver/schemas/chunks/output_image_sd35_large.json:140` (hardcoded default)

**Required Fix:**
1. Pass `safety_result['negative_prompt']` to `pipeline_executor.execute_pipeline()` in Stage 4
2. Add `negative_prompt` parameter to Stage 4 execution call
3. Ensure backward compatibility (default to chunk default if Stage 3 skipped)
4. Test with all safety levels (off, kids, youth)

**Impact:**
- Image quality may be affected (missing quality-related negatives when safety=off)
- Safety filters not fully effective (unwanted content may appear despite Stage 3 checks)
- Kids/youth modes not properly protected

**Estimated Fix Time:** 1-2 hours
**Testing Required:** All safety levels + all output configs (SD3.5, FLUX, GPT-5)

---

## ğŸ”§ CONFIGURATION & REFACTORING

### Stage 2 Model Selection in config.py - **COMPLETED** âœ…
**Status:** âœ… **IMPLEMENTED** - STAGE2_MODE switch added to config.py
**Session:** 53 (2025-11-20)
**Priority:** MEDIUM (enables testing Claude Sonnet vs GPT-OSS 20b)

**What Was Implemented:**
1. âœ… Added `STAGE2_MODE` to `config.py` ("local" | "remote")
   - `local`: GPT-OSS 20b (Ollama, DSGVO-compliant, free)
   - `remote`: Claude Sonnet (OpenRouter, high quality, ~$3/M tokens)
2. âœ… Modified `chunk_builder.py` to read `STAGE2_MODE` for manipulate chunk
   - Overrides model and backend_type based on config
   - Logs which mode is active
3. âœ… Added comment to `manipulate.json` documenting override behavior

**Future Enhancement:**
- **TODO:** Make ALL model selections configurable in `config.py`
  - Currently: Only Stage 2 (manipulate chunk) is configurable
  - Goal: Allow admin to configure models for all stages/chunks in config.py
  - Example: `STAGE1_TRANSLATION_MODEL`, `STAGE1_SAFETY_MODEL`, `STAGE3_SAFETY_MODEL`, etc.
  - Benefit: Easy A/B testing, no code changes needed for model experiments

**Files Modified:**
- `devserver/config.py`: Added STAGE2_MODE (line 76)
- `devserver/schemas/engine/chunk_builder.py`: Added STAGE2_MODE logic (lines 179-200, 235-236)
- `devserver/schemas/chunks/manipulate.json`: Added documentation comment (line 5)

---

## âš ï¸ DEACTIVATED FEATURES (Session 40)

### Vector Fusion UI - **INCOMPLETE / DEACTIVATED**
**Status:** ğŸ”´ **DEACTIVATED** - Multiple unresolved bugs, low priority
**Session:** 40 (2025-11-09)
**Priority:** LOW (relatively unimportant feature per user)

**What Was Implemented:**
- âœ… **Complete UI**: Bubble-based flow visualization with 3 stages
  - Centered input bubble
  - Split flow visualization (Part A + Part B branches)
  - 4-image generation grid (Original, Part A, Part B, Fusion)
  - Vertical scrolling support
- âœ… **Frontend Components**: Phase2VectorFusionInterface.vue (~400 lines)
- âœ… **Pipeline Type Detection**: Frontend correctly detects `text_semantic_split` pipelines
- âœ… **API Integration**: executePipeline() calls working

**What Works:**
- UI renders correctly with bubble flow
- Split operation executes (LLM semantic splitting)
- Frontend receives split results (part_a, part_b)

**What's Broken:**
1. **ğŸ”´ Wrong Language Split**: German text is being split instead of English (translated text)
   - Split should operate on English text (after Stage 1 translation)
   - Currently operates on German original input
   - Root Cause: Stage 1â†’2 data flow passes wrong text field

2. **ğŸ”´ Image Generation Fails**: Backend uses deprecated workflow generator
   - Backend logs show: "Using deprecated comfyui_workflow_generator"
   - Ignores `output_vector_fusion_clip_sd35` chunk defined in pipeline
   - Workflow submitted to ComfyUI but backend doesn't wait for completion
   - Result: Frontend shows 4 image frames with question marks (no images)
   - Root Cause: Migration from deprecated generator to Output-Chunks incomplete

3. **ğŸ”´ Image Retrieval Missing**: No polling or download of generated images
   - Backend submits workflow successfully
   - ComfyUI generates images (visible in ComfyUI interface)
   - Backend never retrieves the results
   - Frontend never receives image URLs

**Technical Details:**
- Pipeline: `text_semantic_split` (Stage 2 semantic splitting)
- Configs Deactivated:
  - `splitandcombinelinear.json` (LERP interpolation)
  - `splitandcombinespherical.json` (SLERP interpolation)
- UI Component: `public/ai4artsed-frontend/src/components/Phase2VectorFusionInterface.vue`
- Output Chunk: `devserver/schemas/chunks/output_vector_fusion_clip_sd35.json` (not being used)

**Why Vector Fusion Requires English:**
- Vector Fusion works in CLIP embedding space
- CLIP embeddings are most precise with English text
- German prompts would produce incorrect semantic vectors
- Stage 1 translation is essential (skip_stage1: false is correct)

**Files Modified:**
- `text_semantic_split.json` - Changed pipeline_type to enable detection
- `Phase2VectorFusionInterface.vue` - Complete UI redesign
- `api.ts` - Fixed status vs success API type mismatch
- `Phase2CreativeFlowView.vue` - Added routing for Vector Fusion UI
- `PipelineExecutionView.vue` - Updated API response handling

**User Decision (Direct Quote):**
> "Wir machen das jetzt so: 1) vermekrke den Arbeitsstand auf einer Problemlist im ToDo. 2) Verschiebe diese workflows nach \"deactivated\". Ich habe keien Lust mit diesem relatriv unwichtigen Teil Stundenlang zu debuggen."

**Deactivated Files:**
- `devserver/schemas/configs/interception/deactivated/splitandcombinelinear.json`
- `devserver/schemas/configs/interception/deactivated/splitandcombinespherical.json`

**Next Steps (If Reactivated):**
1. Fix Stage 1â†’2 data flow to pass English translated text (not German original)
2. Complete migration from deprecated comfyui_workflow_generator to Output-Chunks system
3. Implement image retrieval polling in backend after ComfyUI workflow submission
4. Test full flow: Input â†’ Translation â†’ Split (EN) â†’ Vector Fusion â†’ Display images

**Estimated Fix Time:** 4-6 hours
**Complexity:** High (requires deep backend refactoring)

---

## âœ… COMPLETED FEATURES (Session 39)

### v2.0.0-alpha.1 Release - **COMPLETE**
**Status:** âœ… **SHIPPED** - First fully functional alpha release
**Session:** 39 (2025-11-09)
**Priority:** CRITICAL (milestone release)

**What Was Completed:**
1. **Critical Bugfix: media_type UnboundLocalError**
   - Extracted media_type determination before Stage 3-4 loop
   - Now stage4_only feature works correctly
   - File: `devserver/my_app/routes/schema_pipeline_routes.py` (lines 733-747)

2. **Git Merge & Release:**
   - Merged `feature/schema-architecture-v2` â†’ `main` (113 commits)
   - Created annotated tag `v2.0.0-alpha.1`
   - Pushed to remote repository

3. **Visual Improvements:**
   - Added terminal run separator box (80-char with run metadata)

4. **Frontend Fixes:**
   - HomeView immediate redirect to /select (no old template flash)

5. **Development Workflow:**
   - Created `start_backend.sh` (backend only, port 17801)
   - Created `start_frontend.sh` (frontend only, port 5173)
   - Foreground execution with direct terminal output

**Stashed Features (WIP from Session 37):**
- SSE streaming (postponed per user request)
- Progressive image overlay UI
- Seed management UI (backend complete, frontend incomplete)

**Git Commits:**
- `fix: Extract media_type determination before Stage 3-4 loop`
- `feat: Add visual run separator box`
- `fix: HomeView immediate redirect to /select`
- `feat: Create separate start scripts`
- `docs: Archive Session 37 handover and obsolete docs`
- `Merge feature/schema-architecture-v2` (merge commit)
- `v2.0.0-alpha.1` (annotated tag)

**Testing:**
- âœ… Full 4-stage pipeline execution
- âœ… Image generation functional
- âœ… Files saved to disk
- âœ… Frontend displaying images
- âœ… Clean merge to main
- âœ… Tag pushed successfully

---

## âœ… COMPLETED FEATURES (Sessions 19-36)

### 1. Execution History Tracker - **COMPLETE**
**Status:** âœ… **COMPLETE** - Full Implementation & Testing Done
**Sessions:** 19-24 (2025-11-03)
**Priority:** HIGH (user needs this feature)

**What Was Implemented:**
- **Complete pedagogical journey tracking** from input to output across ALL 4 stages
- **Stage 1**: User input, translation, safety checks
- **Stage 2**: Interception iterations (including Stille Post recursive tracking)
- **Stage 3**: Pre-output safety checks (per output config)
- **Stage 4**: Media generation outputs (per output config)
- **Chronological order** with sequence numbers, timestamps, stage context
- **Two iteration types**: `stage_iteration` (Stage 2 recursive) and `loop_iteration` (Stage 3-4 multi-output)

**Implementation Phases Completed:**
- [x] **Phase 1** (Session 20): Core data structures (ExecutionItem, ExecutionRecord, enums)
- [x] **Phase 2** (Session 20): Tracker implementation & pipeline integration
- [x] **Phase 2.5** (Session 21): Metadata tracking expansion (model_used, backend_used, execution_time)
- [x] **Phase 3** (Session 22): Export API (REST endpoints /api/runs/*)
- [x] **Phase 3.5** (Session 22): Terminology fix (executions â†’ pipeline_runs)
- [x] **Bug Fixes** (Session 23): Stille Post iteration tracking
- [x] **Minor Fixes** (Session 24): pipeline_complete loop_iteration, config_name in API

**Export Formats Implemented:**
- âœ… **JSON**: Fully implemented via /api/runs/{id}/export/json
- â¸ï¸ **XML/PDF/DOCX**: Placeholder (501 Not Implemented) - low priority

**Files Created:**
- `devserver/execution_history/__init__.py`
- `devserver/execution_history/models.py` (219 lines)
- `devserver/execution_history/tracker.py` (589 lines)
- `devserver/execution_history/storage.py` (240 lines)
- `devserver/my_app/routes/execution_routes.py` (334 lines)
- `docs/EXECUTION_TRACKER_ARCHITECTURE.md` (1200+ lines)
- `docs/ITEM_TYPE_TAXONOMY.md`
- `docs/TESTING_REPORT_SESSION_23.md`

**Documentation:**
- Session handover files: SESSION_19_HANDOVER.md through SESSION_22_HANDOVER.md
- Complete testing report: TESTING_REPORT_SESSION_23.md
- Development log: DEVELOPMENT_LOG.md (Sessions 19-24)

**API Endpoints Available:**
- GET /api/runs/list (with filtering and pagination)
- GET /api/runs/{execution_id}
- GET /api/runs/stats
- GET /api/runs/{execution_id}/export/{format}

**Testing Coverage:** ~70% complete
- âœ… Basic workflows (dada, bauhaus, etc.)
- âœ… Stille Post (8 recursive iterations)
- âœ… Loop iteration tracking (Stage 3-4 multi-output)
- âœ… Metadata tracking (model, backend, execution_time)
- â¸ï¸ Multi-output workflows (needs API clarification)
- â­ï¸ Execution mode 'fast' (needs OpenRouter API key)

**Git Commits:**
- a7e5a3b - Phase 1: Core data structures
- 1907fb9 - Phase 2: Tracker integration
- c21bbd0, f5a94b5 - Phase 2.5: Metadata expansion
- 742f04a - Phase 3: Export API
- e3fa9f8 - Terminology fix
- 131427a, 54e8bb5, af22308 - Bug #1 fix & testing
- cbf622f - Minor fixes (OBSERVATION #1 & #2)

**Next Steps (Optional Enhancements):**
- Implement XML/PDF export (currently 501)
- Complete multi-output testing
- Test execution mode 'fast'
- Add frontend UI for browsing execution history

---

### 2. Unified Media Storage - **COMPLETE**
**Status:** âœ… **COMPLETE** - Full Implementation Done
**Session:** 27 (2025-11-04)
**Priority:** HIGH (fixes broken export functionality)

**What Was Implemented:**
- **Backend-agnostic media storage** for ComfyUI, OpenRouter, Replicate, etc.
- **Flat run-based structure**: `exports/json/{run_id}/`
- **Atomic research units**: All files per run in one folder
- **"Run" terminology** (not "execution" due to German connotations)
- **Automatic media download** during pipeline execution
- **UUID-based** for concurrent-safety (workshop scenario)

**Key Features:**
- Auto-detects URL vs prompt_id for media downloads
- Stores metadata.json with complete run information
- Serves media via `/api/media/*` endpoints
- Works with ANY backend (ComfyUI, OpenRouter, future backends)

**Files Created:**
- `devserver/my_app/services/media_storage.py` (414 lines)
- `docs/UNIFIED_MEDIA_STORAGE.md` (documentation)

**Files Modified:**
- `devserver/my_app/routes/schema_pipeline_routes.py` (integration)
- `devserver/my_app/routes/media_routes.py` (rewritten for local storage)

**Storage Structure:**
```
exports/json/{run_uuid}/
â”œâ”€â”€ metadata.json           # Complete run metadata
â”œâ”€â”€ input_text.txt         # Original user input
â”œâ”€â”€ transformed_text.txt   # After interception
â””â”€â”€ output_<type>.<format> # Generated media
```

**API Endpoints:**
- GET /api/media/image/<run_id>
- GET /api/media/audio/<run_id>
- GET /api/media/video/<run_id>
- GET /api/media/info/<run_id>
- GET /api/media/run/<run_id>

**Problems Fixed:**
- âœ… ComfyUI images now persisted locally
- âœ… OpenRouter images stored as actual files
- âœ… Export function works with persisted media
- âœ… Research data properly stored

**Documentation:**
- Session summary: SESSION_27_SUMMARY.md (archived)
- Technical docs: docs/UNIFIED_MEDIA_STORAGE.md

**Next Steps (Optional):**
- Update export_manager.py to use run_id
- Frontend verification of new storage structure

---

### 3. LivePipelineRecorder Migration - **FULLY COMPLETE**
**Status:** âœ… **MIGRATION COMPLETE** - MediaStorage Removed, Single System
**Sessions:** 29 (Initial), 37 (Migration Complete) - (2025-11-04, 2025-11-08)
**Priority:** CRITICAL (fixes complete desynchronization)

**Session 37 Final Migration (2025-11-08):**
- âœ… **MediaStorage completely removed** from pipeline execution
- âœ… **LivePipelineRecorder is now single source of truth**
- âœ… **Frontend displaying images correctly** after bug fix
- âœ… **No more dual-system complexity or duplicate files**

**What Was Completed:**
1. **Session 29:** Created LivePipelineRecorder with unified run_id
   - Sequential entity tracking (01_input.txt â†’ 07_output_image.png)
   - Real-time API endpoints for frontend polling
   - Fixed media polling bug with `wait_for_completion()`

2. **Session 37:** Complete MediaStorage removal
   - Migrated download capabilities to LivePipelineRecorder
   - Added `download_and_save_from_comfyui()` method
   - Added `download_and_save_from_url()` method
   - Updated media_routes.py to use Recorder metadata format
   - Fixed frontend bug accessing media type from API response
   - Resolved Python bytecode caching issues

**Architecture Evolution:**
```
BEFORE (Session 29):
â”œâ”€ ExecutionTracker (exec_*.json)      # OLD system
â”œâ”€ MediaStorage (exports/json/)        # Creates runs, downloads media
â””â”€ LivePipelineRecorder (exports/json/) # Copies from MediaStorage

AFTER (Session 37):
â”œâ”€ ExecutionTracker (exec_*.json)      # Still exists for compatibility
â””â”€ LivePipelineRecorder (exports/json/) # SINGLE SOURCE OF TRUTH
```

**Files Modified (Session 37):**
- `devserver/my_app/services/pipeline_recorder.py` - Added download methods (~200 lines)
- `devserver/my_app/routes/media_routes.py` - Complete rewrite for Recorder format
- `devserver/my_app/routes/schema_pipeline_routes.py` - Removed MediaStorage usage
- `public_dev/js/execution-handler.js` - Fixed media type access bug (line 448)

**API Endpoints:**
- GET /api/pipeline/{run_id}/status - Real-time execution state
- GET /api/pipeline/{run_id}/entity/{type} - Fetch specific entity
- GET /api/pipeline/{run_id}/entities - List all entities
- GET /api/media/image/{run_id} - Serve images from Recorder
- GET /api/media/info/{run_id} - Get media metadata from Recorder

**Test Results (Session 37):**
- Run ID: `1c173019-9437-43fe-bd57-e2612739a8c5`
- All 7 entities created with correct naming (01-07)
- Backend API working (HTTP 200 for all endpoints)
- Frontend displaying images correctly
- No duplicate files, single source of truth validated

**Documentation:**
- Technical docs: `docs/LIVE_PIPELINE_RECORDER.md`
- Session 29: `docs/archive/SESSION_29_*` (archived session docs)
- Session 37: `docs/DEVELOPMENT_LOG.md` (migration completion entry)

**Next Steps (Optional):**
- Consider deprecating old ExecutionTracker after more validation
- Add WebSocket support for real-time frontend updates
- Extend recorder format for video/audio outputs

---

### 4. Phase 2: Multilingual Context Editing - **BACKEND COMPLETE, FRONTEND BROKEN**
**Status:** ğŸš¨ **BACKEND COMPLETE** - Frontend Implementation Wrong, Needs Redesign
**Session:** 36 (2025-11-08)
**Priority:** HIGH (core pedagogical feature) - **BLOCKED by frontend issues**

**What Was Implemented:**
- **Backend API endpoints** for multilingual meta-prompt access
- **Pipeline structure metadata** for dynamic UI rendering
- **Property system fixes** (calmâ†’chill, i18n translation)
- **Frontend components** created (not yet tested end-to-end)

**Backend Endpoints Working:**
- `GET /api/config/<id>/context` - Returns multilingual meta-prompt {en, de}
- `GET /api/config/<id>/pipeline` - Returns pipeline structure metadata
  - `requires_interception_prompt` - Show/hide context editing bubble
  - `input_requirements` - How many text/image inputs needed

**Frontend Components Created (Previous Sessions):**
- `PipelineExecutionView.vue` - Main Phase 2 view with 3 bubbles
- `EditableBubble.vue` - Inline editing component
- `pipelineExecution` store - Phase 2 state management
- `userPreferences` store - Global language management

**ğŸš¨ CRITICAL: Phase 2 Frontend Implementation WRONG**
- **User Feedback:** "you did the stage2 design COMPLETELY wrong, ignoring the organic flow mockup, adding unwanted buttons, also instead of context-prompt there appears: 'Could you please provide the English text you'd like translated into German?'. I will not leave this to you, but add to bugs to be fixed."
- **Problems Identified:**
  - âŒ Ignored organic flow mockup specifications
  - âŒ Added unwanted buttons to the UI
  - âŒ Wrong placeholder text (translation prompt instead of context-prompt)
  - âŒ Fundamental UX design mismatch
- **File Affected:** `public/ai4artsed-frontend/src/views/PipelineExecutionView.vue`
- **Status:** User will handle the frontend implementation redesign
- **Impact:** Phase 2 end-to-end testing **BLOCKED** until frontend is fixed
- **Action Required:** Complete redesign following organic flow mockup
- **âš ï¸ DO NOT attempt to fix without explicit user instruction**

**Property System Fixes:**
- âœ… Removed all "calm" property IDs â†’ "chill"
- âœ… Frontend now uses i18n translation (PropertyBubble, NoMatchState)
- âœ… Fixed PigLatin property pair violation (removed "chill", kept "chaotic")
- âœ… Properties display as translated labels ("wild" not "chaotic")

**Files Modified:**
- Backend: `schema_pipeline_routes.py`, `config_loader.py`, 1 + 10 configs
- Frontend: `PropertyBubble.vue`, `NoMatchState.vue`, 2 stores

**Testing Status:**
- âœ… Backend endpoints tested with curl
- âœ… Property translations fixed in code
- ğŸš¨ Phase 2 end-to-end flow **BLOCKED** (frontend implementation wrong)
- âš ï¸ Phase 1 â†’ Phase 2 navigation NOT YET TESTED
- âš ï¸ Language switching NOT YET TESTED
- âš ï¸ Pipeline execution with edited context NOT YET TESTED

**Next Steps:**
1. **CRITICAL BLOCKER:** Fix Phase 2 Frontend Implementation
   - User will handle the PipelineExecutionView.vue redesign
   - Must follow organic flow mockup specifications
   - Remove unwanted buttons
   - Fix context-prompt placeholder text
   - **âš ï¸ DO NOT attempt without explicit user instruction**

2. **AFTER FRONTEND FIX:** Test Phase 2 end-to-end flow
   - Open `http://localhost:5173/select`
   - Select properties, click config tile
   - Should navigate to `/execute/<configId>`
   - Test language toggle, editing, execution

3. **IF WORKING:** Mark Phase 2 as complete, start Phase 3
4. **IF BROKEN:** Debug before proceeding (Phase 2 foundational for Phase 3)

**Git Commits (Session 36):**
- fix(backend): Add missing config_loader import and fix pipeline_name
- fix: Remove all 'calm' property IDs, replace with 'chill'
- fix(frontend): Use i18n translations for property display
- fix(piglatin): Remove 'chill' property - cannot coexist with 'chaotic'

**Documentation:**
- `docs/HANDOVER.md` - Complete session handover
- `docs/DEVELOPMENT_LOG.md` - Session 36 entry added
- `docs/ARCHITECTURE PART 04 - Pipeline-Types.md` - Pipeline metadata system

---

## ğŸ”¥ IMMEDIATE PRIORITIES (Session 36+)

### 2. Interface Design

**Goal 2: Design Educational Interface**

**Context from User:**
> "Now that the dev system works basically, our priority should be to develop the interface/frontend according to educational purposes. The schema-pipeline-system has been inspired by the idea that ENDUSER may edit or create new configs."

**Key Principles for UI Design:**

1. **Use Stage 2 pipelines as visual guides**
   - `text_transformation.json` shows the flow: input â†’ manipulate â†’ output
   - Pipeline metadata documents what happens at each step

2. **Make the 3-part structure visible and editable**
   - Show TASK_INSTRUCTION (from instruction_type)
   - Show CONTEXT (from config.context)
   - Show PROMPT (user input)
   - Allow editing of configs

3. **Educational transparency**
   - Students should see HOW their prompt is transformed
   - Students should be able to edit configs to create new styles
   - Students should understand the prompt interception concept

4. **Reference files for UI design**
   - `devserver/schemas/pipelines/*.json` - Flow structure
   - `devserver/schemas/configs/interception/*.json` - Config examples
   - `docs/ARCHITECTURE.md` Section 6 - instruction_selector.py docs

### 3. GPT-OSS Stage 3 Implementation (Deferred)

**From Session 14:** Replace llama-guard3 with GPT-OSS in Stage 3
**Status:** Deferred - Focus shifted to interface design
**See:** `docs/devserver_todos.md` for details

---

## ğŸ“ Session 16 Completion Notes

**What Was Fixed:**
- âœ… Restored `single_text_media_generation.json` pipeline (accidentally deprecated in Session 15)
- âœ… Fixed Stage 4 error: "Config 'sd35_large' not found"
- âœ… Tested full 4-stage pipeline: Working correctly
- âœ… Committed fix: commit `6f7d30b`
- âœ… Updated SESSION_HANDOVER.md with Session 16â†’17 context
- âœ… Created PIPELINE_RENAME_PLAN.md (completed in Session 17)

**Key Learnings:**
- Pipeline naming is confusing: "single_prompt_generation" sounds like "generate a prompt" not "generate media FROM a prompt"
- The pipeline was critical for Stage 4 because it provides DIRECT media generation (no text transformation step)
- Output configs (sd35_large, gpt5_image) need this pipeline
- Never deprecate pipeline files without checking all config references first!

**Git Status:**
- Branch: `feature/schema-architecture-v2`
- Commit: `6f7d30b` - "fix: Restore single_prompt_generation pipeline"
- Pushed to remote: âœ…

---

## ğŸ“ Archived TODOs

**Archive Policy:** Completed tasks from old sessions archived for reference

**Archives:**
- **Sessions 1-14 (Full History):** `docs/archive/devserver_todos_sessions_1-14.md` (1406 lines)
  - Sessions 1-8: Various architecture work
  - Session 9: 4-Stage Architecture Refactoring
  - Session 10: Config Folder Restructuring
  - Session 11: Recursive Pipeline + Multi-Output Support
  - Session 12: Project Structure Cleanup + Export Sync
  - Session 13: GPT-OSS Model Research
  - Session 14: GPT-OSS Unified Stage 1 Activation

**See also:** `docs/DEVELOPMENT_LOG.md` for chronological session tracking with costs

---

## ğŸ¯ PRIORITY 1 (Future): Internationalization - Primary Language Selector

**Status:** NEW TODO (from Session 14)
**Context:** German language is currently hardcoded in educational error messages
**Priority:** MEDIUM (works for German deployment, blocks international use)

**Current Issue:**
- Educational blocking messages hardcoded in German (stage_orchestrator.py:330-336)
- Â§86a StGB error template only in German
- System assumes German as primary language

**Proposed Solution:**

### 1. Add to `config.py`
```python
# Primary language for educational content and error messages
PRIMARY_LANGUAGE = "de"  # ISO 639-1 code: de, en, fr, es, etc.

# Supported languages for UI and error messages
SUPPORTED_LANGUAGES = ["de", "en"]
```

### 2. Create Language Templates Directory
```
devserver/schemas/language_templates/
â”œâ”€â”€ de.json  # German templates (default)
â”œâ”€â”€ en.json  # English templates
â””â”€â”€ ...
```

### 3. Template Structure
```json
{
  "safety_blocked": {
    "heading": "Dein Prompt wurde blockiert",
    "why_rule": "WARUM DIESE REGEL?",
    "protection": "Wir schÃ¼tzen dich und andere vor gefÃ¤hrlichen Inhalten."
  }
}
```

### 4. Update Error Messages
- `stage_orchestrator.py`: Replace hardcoded strings with template system
- Load templates based on PRIMARY_LANGUAGE setting
- Fall back to English if language not supported

**Benefits:**
- Enables international deployment (UK, US, France, etc.)
- Maintains German compliance for German deployments
- Single config variable controls all language settings
- Easy to add new languages

**Timeline:** Future enhancement (not blocking current deployment)
**Estimated Time:** 3-4 hours

---

## âœ… RECENTLY COMPLETED

### Session 38 (2025-11-08): GPT-OSS Stage 3 + keep_alive Memory Management
**Status:** âœ… COMPLETE
**Priority:** HIGH (performance optimization + consistency)

**What Was Discovered:**
- GPT-OSS was already configured for Stage 3 via `model_override` in configs
- Only missing piece was `keep_alive` parameter for memory management

**What Was Implemented:**
- Added `keep_alive: "10m"` to all GPT-OSS configs and chunks:
  - `schemas/chunks/manipulate.json` (Stage 2 interception)
  - `schemas/configs/pre_interception/gpt_oss_unified.json` (Stage 1)
  - `schemas/configs/pre_output/text_safety_check_kids.json` (Stage 3)
  - `schemas/configs/pre_output/text_safety_check_youth.json` (Stage 3)

**Current State (All Stages Using GPT-OSS):**
- âœ… Stage 1: GPT-OSS:20b (Translation + Â§86a Safety) with keep_alive
- âœ… Stage 2: GPT-OSS:20b (Prompt Interception) with keep_alive
- âœ… Stage 3: GPT-OSS:20b (Pre-Output Safety kids/youth) with keep_alive
- âœ… Stage 4: Output generation (ComfyUI/API)

**Benefits Achieved:**
- âœ… Single model (GPT-OSS:20b) for all text processing and safety checks
- âœ… Model stays in VRAM for 10 minutes between calls (no loading overhead)
- âœ… Estimated ~2-3s performance improvement per request
- âœ… Unified safety approach across all stages
- âœ… Reduced VRAM thrashing (no model switching)

**Files Modified:**
- `devserver/schemas/chunks/manipulate.json`
- `devserver/schemas/configs/pre_interception/gpt_oss_unified.json`
- `devserver/schemas/configs/pre_output/text_safety_check_kids.json`
- `devserver/schemas/configs/pre_output/text_safety_check_youth.json`

**Testing:**
- âœ… All JSON configs validated
- âœ… Server restarted with new configs
- âœ… Pipeline execution tested successfully

**Git Commit:** [Pending]

---

### Session 17 (2025-11-03): Pipeline Rename to Input-Type Convention
**Status:** âœ… COMPLETE
**Commit:** `bff5da2` - "refactor: Rename pipelines to input-type naming convention"

**What Was Done:**
- Renamed `single_prompt_generation` â†’ `single_text_media_generation`
- Updated 2 output configs: `sd35_large.json`, `gpt5_image.json`
- Updated 7 documentation files
- Deleted deprecated file: `single_prompt_generation.json.deprecated`
- Split ARCHITECTURE.md â†’ ARCHITECTURE PART I.md + PART II.md

**New Pattern:** `[INPUT_TYPE(S)]_media_generation`
- Clear separation: "text" = input type, "media" = output type
- Scalable: Easy to add `image_text_media_generation`, `video_text_media_generation`, etc.
- Self-documenting: Name explicitly describes data flow

**Testing:**
- âœ… Config loader finds pipeline: single_text_media_generation
- âœ… sd35_large config references correct pipeline
- âœ… gpt5_image config references correct pipeline
- âœ… 7 pipelines loaded, 45 configs loaded

**Files Changed:** 13 files (+429 -90 lines)

### Session 14 (2025-11-02): GPT-OSS Unified Stage 1 Activation
**Status:** âœ… COMPLETE & TESTED
**Commit:** `839dc73`

**What Was Done:**
- Created unified GPT-OSS config with full Â§86a StGB legal text
- Added `execute_stage1_gpt_oss_unified()` in stage_orchestrator.py
- Updated schema_pipeline_routes.py to use unified function
- Tested successfully: ISIS blocking, Nazi code 88, legitimate prompts

**ISIS Failure Case from Session 13:** âœ… FIXED

**See:** `docs/DEVELOPMENT_LOG.md` Session 14 for full details

### Session 12 (2025-11-02): Project Structure Cleanup
**Status:** âœ… COMPLETE
**Commit:** `fe3b3c4`

**What Was Done:**
- Archived LoRA experiment + legacy docs
- Moved docs/ and public_dev/ to project root
- Robust start_devserver.sh
- Synced 109 export files from legacy

### Sessions 9-11 (2025-11-01): 4-Stage Architecture
**Status:** âœ… COMPLETE & TESTED

**What Was Implemented:**
- 4-Stage Architecture Refactoring (Stage 1-3 orchestration)
- Recursive Pipeline System ("Stille Post")
- Multi-Output Support (model comparison)

**See:** `docs/archive/devserver_todos_sessions_1-14.md` for full details

---

## ğŸ® MINIGAMES / WAITING ANIMATIONS

### ğŸ¯ Design Principles (Ãœbergreifend)

**Kern-Prinzip: "Sisyphus der Systeme"**

Alle Minigames folgen einem gemeinsamen pÃ¤dagogischen Ansatz:
- **AbwÃ¤rtsdynamik:** Keine vollstÃ¤ndige Heilung mÃ¶glich
- **User kann handeln:** Aber systemische ZerstÃ¶rung lÃ¤uft schneller als individuelle Aktion
- **Realistische Darstellung:** Zeigt die echte Asymmetrie des Problems
- **Sisyphus-Metapher:** KÃ¤mpfen gegen eine Ãœbermacht (wie in "Papers, Please", "This War of Mine")

**Beispiele:**
- **Trees:** 1 Sekunde pro Baumpflanzung, ABER Fabriken wachsen schneller
- **Seltene Erden:** Giftschlamm entfernen, ABER Abbau lÃ¤uft weiter
- **Fair Culture:** (Noch zu definieren - Ã¤hnliches Prinzip)

---

**âš ï¸ KRITISCHE SELBSTREFLEXION - Zu klÃ¤ren:**

**Risiko 1: Resignation statt Handlung**
- FÃ¼hrt die Hoffnungslosigkeit zu LÃ¤hmung?
- Lernen SchÃ¼ler "Es ist aussichtslos, also warum versuchen?"
- Ist das pÃ¤dagogisch kontraproduktiv?

**Risiko 2: Fehlende Handlungsoptionen**
- Minigame zeigt Problem, aber keine LÃ¶sung
- Sollte es konkrete Exit-Strategien geben?
- Links zu realen Organisationen/Initiativen nach dem Spiel?

**Risiko 3: Zu deprimierend fÃ¼r Zielgruppe**
- Ist das fÃ¼r Kids (8-12) / Youth (13-17) angemessen?
- Balance zwischen Realismus und psychischer Belastung?
- Braucht es Hoffnungsmomente?

**MÃ¶gliche LÃ¶sungsansÃ¤tze:**
- [ ] **"Was kann ich wirklich tun?"** - Sektion nach jedem Spiel
  - Recycling-Initiativen (z.B. Fairphone, refurbished Hardware)
  - Fair-Culture-Bewegungen (KÃ¼nstler-Kollektive)
  - Politische Handlungsoptionen (Petitionen, Awareness-Kampagnen)
- [ ] **Kleine Siege zeigen:** User kann temporÃ¤re Verbesserungen erreichen
- [ ] **Kollektive Aktion:** "Du allein kannst es nicht schaffen, aber gemeinsam..."
- [ ] **Systemkritik statt Verzweiflung:** Fokus auf strukturelle Probleme, nicht individuelle Schuld

**Designfrage:** Wie balancieren wir **ehrlichen Realismus** mit **pÃ¤dagogischer ErmÃ¤chtigung**?

---

### Exploitation 1: Seltene Erden (Rare Earths)

**Status:** ğŸ“‹ **PLANNED**
**Datum:** 2026-02-03
**Priority:** MEDIUM (pedagogical feature, not blocking core functionality)

**Konzept:** PÃ¤dagogisches Minigame Ã¼ber das "ZurÃ¼ckbringen" seltener Erden in den Berg

**Game Mechanic (v2 - "Sisyphus der UmweltzerstÃ¶rung"):**
- **Prinzip:** Umwelt vs. genAI - "Tauziehen"-Mechanik mit **AbwÃ¤rtsdynamik**
- **Setting:** Landschaft degradiert kontinuierlich durch Abbau (wie in RealitÃ¤t)
- **User-Aktion:**
  - Giftschlamm aus See baggern
  - In Container bringen
  - Landschaft wird temporÃ¤r gesÃ¼nder
- **ABER: Keine Heilung mÃ¶glich** - AbwÃ¤rtsspirale wie bei "Trees"-Spiel
  - 1 Sekunde pro Giftschlamm-Entfernung
  - ABER: Abbau lÃ¤uft schneller als AufrÃ¤umen
  - Degradierung schreitet immer fort (wie reale Seltene-Erden-Industrie)

**PÃ¤dagogischer Kern:**
- Zeigt die **systemische Hoffnungslosigkeit** des Problems
- User kÃ¤mpft gegen unaufhaltsame ZerstÃ¶rung (Sisyphus-Metapher)
- NICHT naiv-optimistisch ("Alles wird gut wenn wir aufrÃ¤umen!")
- Verdeutlicht: AI-Nutzung â†’ mehr GPU-Nachfrage â†’ mehr Abbau â†’ mehr ZerstÃ¶rung
- User kann handeln, aber nicht gewinnen (realistisch)

**Referenz:** Vergleichbar mit Games wie "Papers, Please" oder "This War of Mine" - moralische Dilemmata ohne "gute" LÃ¶sung

**Details:**
- **Type:** Waiting animation / minigame
- **Educational Goal:** Bewusstsein schaffen fÃ¼r die Umweltauswirkungen des Abbaus seltener Erden fÃ¼r AI-Hardware
- **Thema:** Seltene Erden fÃ¼r GPU/AI-Chips (Neodym, Dysprosium, Terbium, etc.)
- **Integration Point:** WÃ¤hrend lang laufender AI-Generierungsprozesse
- **PÃ¤dagogischer Wert:** Verbindet AI-Nutzung mit realen Ã¶kologischen Kosten

**NÃ¤chste Schritte:**
- [ ] **Design-Entscheidung:** TonalitÃ¤t klÃ¤ren (naiv-verspielt vs. ernst-aufklÃ¤rend)
- [ ] Recherche: Reale UmweltschÃ¤den durch Seltene-Erden-Abbau
- [ ] Game Mechanic finalisieren basierend auf TonalitÃ¤t
- [ ] Artwork/Assets (passend zum AI4ArtsEd Design)
- [ ] Backend: Progress-Tracking fÃ¼r Minigame-State
- [ ] Frontend: Vue-Komponente fÃ¼r Minigame-UI

---

### Exploitation 2: Fair Culture (Web Scraping Ethics)

**Status:** ğŸ“‹ **PLANNED**
**Datum:** 2026-02-03
**Priority:** MEDIUM (pedagogical feature, not blocking core functionality)

**Konzept:** PÃ¤dagogischer Content Ã¼ber Web-Scraping fÃ¼r generative AI, mit Spiel-Mechanik zur KÃ¼nstler-Kompensation

**Details:**
- **Type:** Waiting animation / minigame
- **Educational Goal:** AufklÃ¤rung Ã¼ber AI-Training-Data-Ethik und KÃ¼nstler-Kompensation
- **Thema:** Wie AI-Modelle mit geklauten/gescrapten Kunstwerken trainiert werden
- **Game Mechanic:** Spieler kÃ¶nnten virtuelle KÃ¼nstler "kompensieren" (Noch zu designen)
- **Integration Point:** WÃ¤hrend AI-Model-Loading oder Generierungsprozessen
- **PÃ¤dagogischer Wert:** Kritisches Bewusstsein fÃ¼r Copyright und faire Entlohnung im AI-Zeitalter

**MÃ¶gliche Mechaniken:**
- KÃ¼nstler-Profile mit echten HintergrÃ¼nden (anonymisiert)
- "Kompensations-Punkte" sammeln wÃ¤hrend Wartezeit
- Visualisierung: Wie viele Kunstwerke fÃ¼r Training verwendet wurden
- Link zu Fair-Culture-Initiativen und KÃ¼nstler-Kollektiven

**NÃ¤chste Schritte:**
- [ ] Recherche: Fair-Culture-Bewegung, KÃ¼nstler-Initiativen
- [ ] Game Mechanic Design (Kompensations-System)
- [ ] Content: KÃ¼nstler-Geschichten und Fakten Ã¼ber AI-Training
- [ ] Frontend: Integration in Waiting-Overlay
- [ ] Backend: Optional - Tracking welche Models genutzt werden

---

## ğŸ“ Quick Reference

---

## ğŸŸ¡ REFACTORING: "optimization" â†’ "adaptation"

**Status:** ğŸ“‹ **TODO** - Terminology cleanup
**Datum:** 2026-01-29 (Session 145)
**Priority:** LOW (Code-Hygiene)

### Problem

Backend verwendet "optimization" fÃ¼r Prompt-Adaption an Medienmodelle:
- `optimize_clip_prompt.json` â†’ SD3.5
- `optimize_t5_prompt.json` â†’ Flux
- Weitere fÃ¼r Video/Audio

Frontend/Dokumentation verwendet jetzt korrekt "Adaption/Adaptation".

### Aufgabe

Alle Backend-Referenzen von "optimization/optimize" zu "adaptation/adapt" umbenennen:
- Chunk-Dateien: `optimize_*.json` â†’ `adapt_*.json`
- Code-Referenzen in Python
- Config-Keys

### Betroffene Dateien
```
devserver/schemas/chunks/optimize_clip_prompt*.json
devserver/schemas/chunks/optimize_t5_prompt*.json
devserver/my_app/routes/*.py (Referenzen)
devserver/my_app/engine/*.py (Referenzen)
```

---

**Current Architecture Status:**
- âœ… 4-Stage Pipeline System (Stages 1-4)
- âœ… Config-based system (Chunks â†’ Pipelines â†’ Configs)
- âœ… Backend abstraction (Ollama, ComfyUI, OpenRouter)
- âœ… GPT-OSS Stage 1 (Translation + Â§86a Safety)
- âœ… Stage 3 Hybrid Safety (fast string-match + LLM context)
- âœ… Multi-output support
- âœ… Recursive pipelines

**Next Up:**
1. Replace llama-guard3 with GPT-OSS in Stage 3
2. Implement keep_alive memory management
3. Add language template system

**Documentation:**
- Architecture: `docs/ARCHITECTURE.md`
- Development Log: `docs/DEVELOPMENT_LOG.md` (Sessions 12-14)
- Development Decisions: `docs/DEVELOPMENT_DECISIONS.md`
- Safety Architecture: `docs/safety-architecture-matters.md`

**Archived:**
- Old TODOs: `docs/archive/devserver_todos_sessions_1-14.md`
- Old Dev Log: `docs/archive/DEVELOPMENT_LOG_Sessions_1-11.md`

---

**Created:** 2025-10-26
**Last Major Cleanup:** 2025-11-02 Session 14
**Status:** Clean and concise (down from 1406 lines to ~230 lines)
