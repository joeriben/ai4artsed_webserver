{
  "name": "output_image_flux2_fp8",
  "type": "output_chunk",
  "backend_type": "diffusers",
  "media_type": "image",
  "description": "Flux 2 Dev FP8 via HuggingFace Diffusers - Fast inference with quantized model",

  "diffusers_config": {
    "model_id": "silveroxides/FLUX.2-dev-fp8_scaled",
    "pipeline_class": "Flux2Pipeline",
    "torch_dtype": "bfloat16",
    "enable_attention_slicing": true,
    "enable_vae_tiling": false
  },

  "input_mappings": {
    "prompt": {
      "source": "{{PREVIOUS_OUTPUT}}",
      "description": "Positive prompt - main image description"
    },
    "negative_prompt": {
      "default": "text, watermark",
      "description": "Negative prompt - what to avoid"
    },
    "width": {
      "default": 1024,
      "description": "Image width in pixels"
    },
    "height": {
      "default": 1024,
      "description": "Image height in pixels"
    },
    "steps": {
      "default": 20,
      "description": "Number of sampling steps"
    },
    "cfg": {
      "default": 1,
      "description": "Classifier Free Guidance scale"
    },
    "seed": {
      "default": "random",
      "description": "Seed for reproducibility"
    }
  },

  "output_mapping": {
    "output_type": "image",
    "format": "png",
    "description": "Generated PNG image"
  },

  "meta": {
    "estimated_duration_seconds": "15",
    "quality_rating": 4,
    "requires_gpu": true,
    "gpu_vram_mb": 20000,
    "model_file": "silveroxides/FLUX.2-dev-fp8_scaled (HuggingFace)",
    "recommended_resolution": "1024x1024",
    "supported_resolutions": [
      "768x768",
      "1024x1024",
      "1024x2048",
      "2048x1024"
    ],
    "notes": "FP8 quantized Flux 2 Dev - 50% less VRAM than full model while maintaining quality."
  }
}
