{
  "name": "output_image_attention_cartography_diffusers",
  "type": "output_chunk",
  "backend_type": "diffusers",
  "media_type": "image",
  "description": "Attention Cartography via Diffusers — generates image with cross-attention map extraction. Returns image + per-token attention heatmaps at selected layers and timesteps.",

  "diffusers_config": {
    "model_id": "stabilityai/stable-diffusion-3.5-large",
    "pipeline_class": "StableDiffusion3Pipeline",
    "attention_mode": true,
    "capture_layers": [3, 9, 17],
    "capture_every_n_steps": 1
  },

  "input_mappings": {
    "prompt": {
      "source": "{{PREVIOUS_OUTPUT}}",
      "description": "Text prompt — tokenized and used for attention map labeling"
    },
    "seed": {
      "default": "random",
      "description": "Seed for reproducibility"
    },
    "steps": {
      "default": 25,
      "description": "Number of sampling steps"
    },
    "cfg": {
      "default": 4.5,
      "description": "Classifier Free Guidance scale"
    },
    "negative_prompt": {
      "default": "",
      "description": "Negative prompt"
    },
    "width": {
      "default": 1024,
      "description": "Image width in pixels"
    },
    "height": {
      "default": 1024,
      "description": "Image height in pixels"
    }
  },

  "output_mapping": {
    "output_type": "image",
    "format": "png",
    "description": "Generated PNG image with attention map data in metadata"
  },

  "meta": {
    "estimated_duration_seconds": "30-50",
    "requires_gpu": true,
    "gpu_vram_mb": 8000,
    "notes": "Custom attention processor replaces JointAttnProcessor2_0 on selected transformer blocks. Computes manual softmax(QK^T/sqrt(d)) to extract text->image cross-attention submatrix. ~20-30% slower than SDPA. Attention maps are 64x64 (patch resolution) per token, captured at 3 layers x 5 timesteps = ~120MB total."
  }
}
