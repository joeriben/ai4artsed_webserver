<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Programmierer-Dokumentation: AI4ArtsEd Webserver</title>
    <style>
        body { font-family: sans-serif; line-height: 1.6; padding: 20px; max-width: 1000px; margin: auto; }
        h1, h2, h3 { color: #333; }
        code { background-color: #f4f4f4; padding: 2px 6px; border-radius: 4px; }
        pre { background-color: #f4f4f4; padding: 15px; border-radius: 5px; overflow-x: auto; }
        .toc { border: 1px solid #ccc; padding: 10px 20px; border-radius: 5px; background-color: #f9f9f9; }
        .toc ul { list-style-type: none; padding-left: 0; }
        .toc > ul > li > a { font-weight: bold; }
        .toc ul ul { padding-left: 20px; }
        .warn { border-left: 5px solid #f0ad4e; padding: 10px; background-color: #fcf8e3; }
        .info { border-left: 5px solid #5bc0de; padding: 10px; background-color: #eef7f9; }
        .lang-switch { text-align: right; margin-bottom: 20px; }
    </style>
</head>
<body>

    <div class="lang-switch">
        <a href="programmers_en.html">English Version</a>
    </div>

    <h1>Programmierer-Dokumentation: AI4ArtsEd Webserver</h1>

    <div class="toc">
        <h2>Inhaltsverzeichnis</h2>
        <ul>
            <li><a href="#einfuehrung">1. Einführung und Systemarchitektur</a>
                <ul>
                    <li><a href="#systemueberblick">1.1. Systemüberblick</a></li>
                    <li><a href="#technologie-stack">1.2. Technologie-Stack</a></li>
                    <li><a href="#verzeichnisstruktur">1.3. Verzeichnisstruktur</a></li>
                </ul>
            </li>
            <li><a href="#server-backend">2. Server-Backend (Flask/Waitress)</a>
                <ul>
                    <li><a href="#startpunkt">2.1. Startpunkt (server.py)</a></li>
                    <li><a href="#anwendungs-factory">2.2. Anwendungs-Factory (__init__.py)</a></li>
                    <li><a href="#routing">2.3. Routing (routes)</a></li>
                    <li><a href="#services">2.4. Services</a></li>
                </ul>
            </li>
            <li><a href="#workflow-logik">3. Kernlogik: Workflows</a>
                <ul>
                    <li><a href="#workflow-management">3.1. Workflow-Management (workflow_logic_service.py)</a></li>
                    <li><a href="#eco-vs-fast">3.2. Eco- vs. Fast-Modus</a></li>
                    <li><a href="#hidden-commands">3.3. "Hidden Commands" im Prompt</a></li>
                </ul>
            </li>
            <li><a href="#interaktion-swarmui">4. Interaktion mit SwarmUI/ComfyUI</a>
                <ul>
                    <li><a href="#comfyui-service">4.1. ComfyUI Service (comfyui_service.py)</a></li>
                    <li><a href="#custom-nodes">4.2. Custom Nodes</a></li>
                </ul>
            </li>
            <li><a href="#sicherheitsfeatures">5. Sicherheitsfeatures: Eine mehrstufige Verteidigung</a></li>
            <li><a href="#weitere-features">6. Weitere wichtige Features</a>
                <ul>
                    <li><a href="#bild-upload">6.1. Bild-Upload und -Analyse</a></li>
                    <li><a href="#exportfunktion">6.2. Exportfunktion</a></li>
                    <li><a href="#internationalisierung">6.3. Internationalisierung (i18n)</a></li>
                </ul>
            </li>
             <li><a href="#dev-log">7. Development Log (Zusammenfassung)</a></li>
        </ul>
    </div>

    <h2 id="einfuehrung">1. Einführung und Systemarchitektur</h2>

    <h3 id="systemueberblick">1.1. Systemüberblick</h3>
    <p>
        Der AI4ArtsEd Webserver ist eine Python-basierte Webanwendung, die als benutzerfreundliches Interface für die generative KI-Plattform SwarmUI/ComfyUI dient. Er abstrahiert die Komplexität von ComfyUI-Workflows und bietet eine vereinfachte, auf die Ziele des Projekts zugeschnittene Oberfläche.
    </p>
    <p>
        Die Kernidee ist, eine Brücke zwischen Endanwendern (Künstler, Pädagogen, Schüler) und der mächtigen, aber technischen ComfyUI-Engine zu schlagen. Der Server erreicht dies durch:
    </p>
    <ul>
        <li>Eine webbasierte, intuitive Benutzeroberfläche.</li>
        <li>Dynamische Manipulation von ComfyUI-JSON-Workflows basierend auf Benutzereingaben.</li>
        <li>Integration von Sicherheits- und Moderations-Layern.</li>
        <li>Abstraktion von technischen Details wie Modell-Auswahl und Seed-Kontrolle.</li>
        <li>Bereitstellung von Zusatzfunktionen wie Bildanalyse, Export und mehrsprachige Unterstützung.</li>
    </ul>
    <p class="info">
        <strong>Das zentrale Verhältnis:</strong> Der Webserver ist kein eigenständiger Generator von KI-Inhalten. Er ist ein <strong>intelligenter Orchestrator und Manipulator</strong>. Er nimmt Benutzereingaben entgegen, wählt einen passenden ComfyUI-Workflow aus, modifiziert diesen zur Laufzeit und reicht ihn zur Ausführung an den ComfyUI-Backend-Service weiter. Die Ergebnisse (Bilder, Texte) werden dann vom ComfyUI-Service abgeholt und dem Benutzer angezeigt.
    </p>

    <h3 id="technologie-stack">1.2. Technologie-Stack</h3>
    <ul>
        <li><strong>Backend-Framework:</strong> Flask</li>
        <li><strong>WSGI-Server:</strong> Waitress (für den Production-Einsatz)</li>
        <li><strong>KI-Backend:</strong> SwarmUI / ComfyUI</li>
        <li><strong>LLM-Interaktion:</strong> Ollama (für lokale Modelle), OpenRouter (für Cloud-Modelle)</li>
        <li><strong>Frontend:</strong> HTML, CSS, JavaScript (serverseitig gerendert und statisch ausgeliefert)</li>
    </ul>

    <h3 id="verzeichnisstruktur">1.3. Verzeichnisstruktur</h3>
    <pre>
/
├── server/                  # Haupt-Backend-Code
│   ├── my_app/              # Modulare Anwendungsstruktur
│   │   ├── routes/          # Flask Blueprints für verschiedene Endpunkte
│   │   ├── services/        # Geschäftslogik (ComfyUI, Ollama, Workflows)
│   │   └── utils/           # Hilfsfunktionen
│   ├── config.py            # Konfigurationsvariablen
│   └── server.py            # Haupteinstiegspunkt, startet den Waitress-Server
├── scripts/                 # Hilfsskripte für Wartung und Metadaten-Generierung
├── public/                  # Statische Dateien (HTML, CSS, JS, Bilder)
│   └── documentation/       # Speicherort für diese Dokumentation
├── workflows_legacy/               # Sammlung der ComfyUI-JSON-Workflows
│   └── metadata.json        # Metadaten für Workflows (Namen, Beschreibungen)
└── requirements.txt         # Python-Abhängigkeiten
    </pre>
    <p>
        Zusätzlich interagiert das System mit den Custom Nodes in <code>/home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/custom_nodes/ai4artsed_comfyui/</code>.
    </p>

    <h2 id="server-backend">2. Server-Backend (Flask/Waitress)</h2>

    <h3 id="startpunkt">2.1. Startpunkt (server.py)</h3>
    <p>
        Die Datei <code>server/server.py</code> ist der Einstiegspunkt. Sie importiert die Anwendungs-Factory <code>create_app</code> aus <code>my_app</code> und startet den <strong>Waitress Production-Server</strong>. Die Umstellung von Flasks eingebautem Development-Server auf Waitress (siehe Dev-Log vom 29.6.) war ein wichtiger Schritt zur Stabilisierung des Systems für den Mehrbenutzerbetrieb.
    </p>

    <h3 id="anwendungs-factory">2.2. Anwendungs-Factory (__init__.py)</h3>
    <p>
        In <code>server/my_app/__init__.py</code> wird die Flask-Anwendung nach dem Factory-Pattern erstellt. Dies fördert die Modularität und Testbarkeit. Hier werden:
    </p>
    <ul>
        <li>Die Flask-App instanziiert.</li>
        <li>CORS (Cross-Origin Resource Sharing) konfiguriert, um Anfragen vom Frontend zu erlauben.</li>
        <li>Alle Blueprints (Routen-Module) registriert.</li>
        <li>Logging konfiguriert.</li>
    </ul>

    <h3 id="routing">2.3. Routing (routes)</h3>
    <p>
        Die API-Endpunkte sind in Blueprints im Verzeichnis <code>server/my_app/routes/</code> organisiert. Der wichtigste Blueprint ist <code>workflow_routes.py</code>:
    </p>
    <ul>
        <li><code>/list_workflows</code>: Listet alle verfügbaren JSON-Workflows auf.</li>
        <li><code>/workflow_metadata</code>: Liefert die Metadaten (Namen, Kategorien, etc.) aus <code>workflows_legacy/metadata.json</code>.</li>
        <li><code>/run_workflow</code>: Der zentrale Endpunkt. Nimmt den Prompt, den ausgewählten Workflow und andere Parameter entgegen, orchestriert die gesamte Logik und reicht den Job an ComfyUI weiter.</li>
        <li><code>/workflow-status/&lt;prompt_id&gt;</code>: Fragt den Status eines laufenden Jobs bei ComfyUI ab.</li>
        <li><code>/analyze_image</code>: Nimmt ein Bild entgegen und sendet es zur Analyse an den Ollama-Service.</li>
        <li><code>/comfyui/&lt;path:path&gt;</code>: Ein Proxy, der Anfragen direkt an das ComfyUI-Backend weiterleitet. Dies ist entscheidend, damit das Frontend z.B. generierte Bilder direkt von ComfyUI laden kann, ohne dass der Flask-Server als zwischengeschalteter Downloader agieren muss.</li>
    </ul>

    <h3 id="services">2.4. Services</h3>
    <p>
        Die Geschäftslogik ist in Service-Klassen in <code>server/my_app/services/</code> gekapselt. Dies trennt die Routen-Handler von der eigentlichen Arbeit.
    </p>
    <ul>
        <li><strong>workflow_logic_service.py:</strong> Das Herzstück der Anwendung. Lädt und manipuliert Workflow-JSONs.</li>
        <li><strong>comfyui_service.py:</strong> Kümmert sich um die gesamte HTTP-Kommunikation mit der ComfyUI-API.</li>
        <li><strong>ollama_service.py:</strong> Schnittstelle zu lokalen und via OpenRouter angebundenen LLMs für Aufgaben wie Übersetzung, Sicherheit und Bildanalyse.</li>
        <li><strong>export_manager.py:</strong> Verwaltet den Export von Ergebnissen.</li>
        <li><strong>inpainting_service.py:</strong> Speziallogik für Inpainting-Workflows.</li>
        <li><strong>model_path_resolver.py:</strong> Intelligente Suchroutine, um Modelle zu finden, auch wenn sie nicht am erwarteten Ort liegen.</li>
    </ul>

    <h2 id="workflow-logik">3. Kernlogik: Workflows</h2>

    <h3 id="workflow-management">3.1. Workflow-Management (workflow_logic_service.py)</h3>
    <p>
        Dieser Service ist verantwortlich für die dynamische Anpassung der Workflows. Der Prozess für eine Anfrage an <code>/run_workflow</code> sieht grob so aus:
    </p>
    <ol>
        <li>Laden der Basis-JSON-Datei des ausgewählten Workflows.</li>
        <li>Anwenden des <strong>Eco- oder Fast-Modus</strong> durch Austauschen der Modellnamen im Workflow.</li>
        <li>Injizieren des Benutzer-Prompts in den dafür vorgesehenen Knoten.</li>
        <li>Anpassen der Bild-Dimensionen basierend auf dem gewählten Seitenverhältnis.</li>
        <li>Setzen des <strong>Seeds</strong> basierend auf der Benutzerauswahl (Zufall, Standard, Fix).</li>
        <li>Aktivieren des <strong>Sicherheitslevels</strong> in der Custom Safety Node.</li>
        <li>Anreichern der <strong>negativen Prompts</strong> mit Standard- und sicherheitsrelevanten Begriffen.</li>
        <li>Auflösen von Modellpfaden, um die Resilienz zu erhöhen.</li>
        <li>Anwenden von <strong>"Hidden Commands"</strong> aus dem Prompt.</li>
        <li>Übergeben des final modifizierten Workflow-JSON an den <code>comfyui_service</code>.</li>
    </ol>

    <h3 id="eco-vs-fast">3.2. Eco- vs. Fast-Modus</h3>
    <p>
        Dieses Feature (siehe Dev-Log 2.7.25) erlaubt einen dynamischen Wechsel zwischen lokalen (Eco) und Cloud-basierten (Fast) LLMs.
    </p>
    <ul>
        <li><strong>Eco-Modus:</strong> Nutzt lokale Modelle via Ollama. Die <code>workflow_logic_service</code> durchsucht den Workflow nach Knoten, die Cloud-Modelle verwenden, und ersetzt sie durch ihre lokalen Äquivalente, die in <code>config.py</code> (<code>OPENROUTER_TO_OLLAMA_MAP</code>) definiert sind.</li>
        <li><strong>Fast-Modus:</strong> Nutzt leistungsfähigere Cloud-Modelle via OpenRouter. Hier geschieht das Gegenteil: Lokale Modellnamen werden durch ihre Cloud-Pendants (<code>OLLAMA_TO_OPENROUTER_MAP</code>) ersetzt. Es gibt eine intelligente Fallback-Logik, um ein passendes Modell zu finden, falls kein direktes Äquivalent existiert.</li>
    </ul>

    <h3 id="hidden-commands">3.3. "Hidden Commands" im Prompt</h3>
    <p>
        Um die Benutzeroberfläche schlank zu halten und dennoch Power-Usern mehr Kontrolle zu geben, wurden "Hidden Commands" eingeführt (Dev-Log 19.7.25 & 21.7.25). Diese werden direkt in das Prompt-Feld geschrieben und vom Server (<code>helpers.py:parse_hidden_commands</code>) geparst, bevor der Prompt weiterverarbeitet wird.
    </p>
    <ul>
        <li><code>#notranslate#</code>: Überspringt die automatische Übersetzung.</li>
        <li><code>#cfg:x#</code>, <code>#steps:x#</code>, <code>#seed:x#</code>: Überschreiben die UI-Einstellungen für den KSampler im gesamten Workflow.</li>
        <li><code>#negative:begriffe#</code>: Hängt zusätzliche Begriffe an alle negativen Prompts im Workflow an.</li>
        <li><code>#loop:x#</code>: (Geplant) Soll den Workflow x-mal ausführen.</li>
    </ul>
    <p class="warn">
        <strong>Wichtig:</strong> Diese Befehle werden serverseitig verarbeitet und überschreiben die Einstellungen aus dem Frontend. Dies ist ein mächtiges Werkzeug für Debugging und fortgeschrittene Nutzung.
    </p>

    <h2 id="interaktion-swarmui">4. Interaktion mit SwarmUI/ComfyUI</h2>

    <h3 id="comfyui-service">4.1. ComfyUI Service (comfyui_service.py)</h3>
    <p>
        Dieser Service ist eine reine API-Wrapper-Klasse für die ComfyUI-HTTP-API. Er stellt Methoden bereit für:
    </p>
    <ul>
        <li><code>submit_workflow</code>: Sendet ein Workflow-JSON an den <code>/prompt</code>-Endpunkt von ComfyUI.</li>
        <li><code>get_history</code>: Fragt den <code>/history/&lt;prompt_id&gt;</code>-Endpunkt ab, um den Status und die Ergebnisse eines Jobs zu erhalten.</li>
        <li><code>download_media</code>: Lädt generierte Medien (Bilder etc.) von ComfyUI.</li>
        <li><code>proxy_request</code>: Leitet Anfragen direkt an ComfyUI weiter.</li>
    </ul>

    <h3 id="custom-nodes">4.2. Custom Nodes</h3>
    <p>
        Ein wesentlicher Teil der Projektlogik ist in spezialisierte, wiederverwendbare Custom Nodes für ComfyUI ausgelagert. Diese befinden sich im Verzeichnis <code>/home/joerissen/ai/SwarmUI/dlbackend/ComfyUI/custom_nodes/ai4artsed_comfyui/</code>. Sie ermöglichen es, komplexe Logik direkt in die Workflows zu integrieren und vom Webserver aus zu steuern.
    </p>
    <p>Wichtige Custom Nodes sind:</p>
    <ul>
        <li><code>ai4artsed_switch_promptsafety.py</code>: Das Kernstück der Sicherheitsfeatures. Diese Node erhält vom Webserver das Sicherheitslevel ('off', 'youth', 'kids') und manipuliert basierend darauf den durchfließenden Prompt.</li>
        <li><code>ai4artsed_prompt_interception.py</code>: Ermöglicht die dynamische Auswahl von LLM-Modellen (lokal vs. cloud) direkt im Workflow.</li>
        <li><code>ai4artsed_image_analysis.py</code>: Analysiert ein Bild und gibt eine textuelle Beschreibung zurück.</li>
        <li>Weitere Nodes für spezifische Aufgaben wie Text-Remixing, Konditionierungs-Fusion etc.</li>
    </ul>
    <p class="info">
        Die Verwendung von Custom Nodes ist ein cleverer Architektur-Entscheid. Anstatt die gesamte Logik im Webserver zu implementieren, wird sie in modulare, im ComfyUI-Graphen sichtbare und wiederverwendbare Komponenten verlagert. Der Webserver agiert dann als "Fernsteuerung" für diese Nodes.
    </p>

    <h2 id="sicherheitsfeatures">5. Sicherheitsfeatures: Eine mehrstufige Verteidigung</h2>
    <p>
        Sicherheit ist ein zentrales Anliegen des Projekts. Anstatt eines einzelnen Filters wurde eine tiefgestaffelte, mehrstufige Sicherheits-Pipeline implementiert, die sowohl serverseitig als auch innerhalb des ComfyUI-Workflows agiert. Dies adressiert das Problem, dass einfache Filter umgangen werden können.
    </p>
    <p class="info">
        <strong>Die Sicherheits-Pipeline im Detail:</strong> Jede Benutzereingabe durchläuft die folgenden Schritte in exakter Reihenfolge, bevor ein Bild generiert wird.
    </p>
    
    <ol>
        <li><strong>Stufe 1: Serverseitige Vorverarbeitung (in <code>ollama_service.py</code>)</strong>
            <ul>
                <li><strong>Schritt 1.1: Übersetzung nach Englisch:</strong> Der ursprüngliche Prompt wird zuerst mit dem <code>TRANSLATION_MODEL</code> (<code>gemma2:9b</code>) ins Englische übersetzt. Dies ist entscheidend, da die nachfolgenden Sicherheitsmodelle primär auf Englisch trainiert sind. Die Übersetzungsanweisung in <code>config.py</code> ist hochspezifisch, um die semantische Struktur und spezielle Syntax zu erhalten.</li>
                <li><strong>Schritt 1.2: Guard-Modell-Prüfung:</strong> Der <strong>übersetzte</strong> englische Prompt wird an ein dediziertes Guard-Modell, <code>SAFETY_MODEL</code> (<code>llama-guard-3:8b</code>), gesendet. Dieses Modell ist speziell darauf trainiert, unsichere Inhalte zu erkennen. Wenn dieses Modell den Prompt als problematisch einstuft, wird der gesamte Prozess <strong>sofort abgebrochen</strong> und eine Fehlermeldung an den Benutzer zurückgegeben. Nur als sicher eingestufte Prompts gelangen zur nächsten Stufe.</li>
            </ul>
        </li>
        <br>
        <li><strong>Stufe 2: Serverseitige Workflow-Manipulation (in <code>workflow_logic_service.py</code>)</strong>
            <ul>
                <li><strong>Schritt 2.1: Konfiguration der Safety Node:</strong> Der Server findet die Custom Node <code>ai4artsed_switch_promptsafety</code> im Workflow und stellt deren Parameter <code>filter_level</code> auf die vom Benutzer gewählte Stufe ('off', 'youth', 'kids'). Dies bereitet die nächste Sicherheitsstufe vor, die erst innerhalb von ComfyUI aktiv wird.</li>
                <li><strong>Schritt 2.2: Induzierung von negativen Prompts:</strong> Dies ist ein entscheidendes, proaktives Sicherheitsnetz. Die Funktion <code>enhance_negative_prompts</code> reichert die negativen Prompts aller Sampler-Knoten im Workflow an:
                    <ul>
                        <li><strong>Immer:</strong> Es werden die <code>DEFAULT_NEGATIVE_TERMS</code> aus <code>config.py</code> hinzugefügt (z.B. "blurry, bad quality"), um die allgemeine Bildqualität zu verbessern.</li>
                        <li><strong>Bedingt:</strong> Wenn der Sicherheitslevel 'youth' oder 'kids' ist, werden zusätzlich die umfangreichen, spezifischen Wortlisten aus <code>SAFETY_NEGATIVE_TERMS</code> in <code>config.py</code> hinzugefügt. Für 'kids' ist diese Liste besonders umfassend und enthält Begriffe aus den Bereichen Gewalt, Horror, psychische Not etc. Dies verhindert, dass die KI problematische Elemente generiert, selbst wenn der positive Prompt harmlos erscheint.</li>
                    </ul>
                </li>
            </ul>
        </li>
        <br>
        <li><strong>Stufe 3: In-Workflow Prompt-Manipulation (in <code>ai4artsed_switch_promptsafety.py</code>)</strong>
            <ul>
                <li><strong>Schritt 3.1: Ausführung in ComfyUI:</strong> Nachdem der manipulierte Workflow an ComfyUI übergeben wurde, wird die Custom Node <code>ai4artsed_switch_promptsafety</code> aktiv. Sie erhält den bereits übersetzten und von Stufe 1 als sicher eingestuften Prompt.</li>
                <li><strong>Schritt 3.2: Finale Transformation:</strong> Basierend auf dem eingestellten <code>filter_level</code> führt die Node eine finale LLM-Operation durch:
                    <ul>
                        <li><strong>'youth':</strong> Der Prompt wird gemäß den detaillierten Anweisungen in <code>MANIPULATION_INSTRUCTIONS["youth"]</code> umformuliert. Ziel ist es, problematische Darstellungen zu entschärfen und zu abstrahieren, ohne die kreative Essenz komplett zu verlieren.</li>
                        <li><strong>'kids':</strong> Hier greifen noch strengere Regeln aus <code>MANIPULATION_INSTRUCTIONS["kids"]</code>. Wenn der Prompt als potenziell angstauslösend für Kinder eingestuft wird, wird er <strong>komplett verworfen</strong> und durch einen fest kodierten, sicheren Fallback-Prompt ersetzt ("Eine kleine, verängstigte Katze..."). Dies ist die letzte und härteste Verteidigungslinie, um die Generierung schädlicher Inhalte zu verhindern.</li>
                    </ul>
                </li>
            </ul>
        </li>
    </ol>
    <p class="warn">
        <strong>Zusammenfassend:</strong> Das System verlässt sich nicht auf einen einzigen Filter. Es ist eine Kaskade aus präventiver Prüfung (Guard-Modell), proaktiver Absicherung (negative Prompts) und reaktiver Manipulation (Safety Node), die sicherstellt, dass nur sorgfältig geprüfte und angepasste Prompts die finale Bildgenerierung erreichen.
    </p>

    <h2 id="weitere-features">6. Weitere wichtige Features</h2>

    <h3 id="bild-upload">6.1. Bild-Upload und -Analyse</h3>
    <p>
        (Dev-Log 29.6.25, 17.6.25) Benutzer können Bilder hochladen. Die Verarbeitung hängt vom ausgewählten Workflow ab:
    </p>
    <ul>
        <li><strong>Standard-Workflow:</strong> Das Bild wird an den <code>ollama_service</code> gesendet, der mit einem Vision-Modell (<code>ANALYSIS_MODEL</code>) eine Textbeschreibung des Bildes generiert. Diese Beschreibung wird dann an den Text-Prompt des Benutzers angehängt. Das Bild selbst wird nicht verwendet.</li>
        <li><strong>Inpaint-Workflow:</strong> Das System erkennt Inpaint-Workflows (anhand des Modellnamens und dem Vorhandensein einer "LoadImage"-Node). In diesem Fall wird das Bild nicht analysiert, sondern direkt in die "LoadImage"-Node des Workflows injiziert, um als Basis für den Inpainting-Prozess zu dienen.</li>
    </ul>

    <h3 id="exportfunktion">6.2. Exportfunktion</h3>
    <p>
        (Dev-Log 5.7.25, 14.7.25) Ergebnisse werden automatisch auf dem Server im Verzeichnis <code>exports/</code> gespeichert. Der <code>export_manager.py</code> kümmert sich darum, die generierten Bilder und Metadaten (Prompt, Seed, etc.) zu sammeln und in verschiedenen Formaten (HTML, PDF, DOCX, XML) abzulegen. Dies dient der Nachvollziehbarkeit und der Forschungsdatenerhebung.
    </p>

    <h3 id="internationalisierung">6.3. Internationalisierung (i18n)</h3>
    <p>
        (Dev-Log 5.7.25, 19.7.25, 21.7.25) Das System ist bilingual (Deutsch/Englisch) ausgelegt. Die Herausforderung, dies mit der dynamischen Natur der Workflows zu verbinden, wurde durch einen manuellen Ansatz gelöst:
    </p>
    <ul>
        <li>Workflow-Namen, -Kategorien und -Beschreibungen werden in beiden Sprachen in der zentralen Datei <code>workflows_legacy/metadata.json</code> gepflegt.</li>
        <li>Ein Skript (vermutlich <code>scripts/generate_metadata.py</code>) hilft bei der Verwaltung dieser Datei.</li>
        <li>Das Frontend lädt diese Metadaten und zeigt die entsprechende Sprache an. Falls kein Eintrag für einen Workflow existiert, wird der Dateiname als Fallback verwendet.</li>
    </ul>
    <p class="warn">
        Die Versuche, dies vollständig zu automatisieren, scheiterten an der Komplexität und den Kosten, was zu der aktuellen, stabileren manuellen Lösung führte.
    </p>

    <h2 id="dev-log">7. Development Log (Zusammenfassung)</h2>
    <p>
        Das bereitgestellte Development Log ist eine wertvolle Ressource, um die Evolution des Projekts nachzuvollziehen. Wichtige Erkenntnisse daraus sind:
    </p>
    <ul>
        <li><strong>Iterative Entwicklung:</strong> Features wurden schrittweise hinzugefügt und verfeinert.</li>
        <li><strong>Pragmatische Entscheidungen:</strong> Gescheiterte Versuche (z.B. stateful-Server, automatische i18n) führten zu einfacheren, aber robusteren Lösungen. Die Entwickler waren bereit, komplexe Ansätze zu verwerfen, wenn sie sich als unpraktikabel oder zu teuer erwiesen.</li>
        <li><strong>Fokus auf Sicherheit:</strong> Ein signifikanter Teil der Entwicklung widmete sich der Implementierung mehrstufiger Sicherheitsmechanismen.</li>
        <li><strong>Benutzerfreundlichkeit vs. Funktionalität:</strong> Es wurde bewusst darauf geachtet, die Oberfläche einfach zu halten (z.B. keine direkte Seed-Eingabe, Hidden Commands für Power-User), um die Zielgruppe nicht zu überfordern.</li>
        <li><strong>Refactoring:</strong> Die Notwendigkeit, Code zu refaktorieren (z.B. <code>server.py</code>, <code>index.html</code>), wurde erkannt und umgesetzt, um die Wartbarkeit zu gewährleisten.</li>
    </ul>

</body>
</html>
